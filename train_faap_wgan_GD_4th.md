# train_faap_wgan_GD_4th 변경 요약 (vs 3rd)

## 핵심 변경: 단방향 Wasserstein 손실

### 3rd (양방향)
```python
return (sorted_f - sorted_m).abs().mean()  # |여성 - 남성|
```
- 두 분포 간 거리 최소화
- 남성↓ 또는 여성↑ 모두 가능

### 4th (단방향)
```python
return F.relu(sorted_m - sorted_f).mean()  # max(남성 - 여성, 0)
```
- 여성 < 남성일 때만 손실 발생
- 여성만 끌어올림, 남성 성능 유지

## 하이퍼파라미터 변경
| 파라미터 | 3rd | 4th |
|----------|-----|-----|
| `lambda_w` | 0.1 | 0.2 |

## 기대 효과
- 남성 AP/AR 유지
- 여성 AP/AR 향상
- 전체 평균 성능 상승

---

# 파이프라인 및 Loss 수식 정리

## 1. 전체 파이프라인 구조

### 입력 (Inputs)
- 이미지 x
- 성별 레이블 g (0: male, 1: female)
- 객체 검출 타겟 y (Bounding Boxes, Classes)

### 모델 구성 (Models)
1. **Perturbation Generator (G)**
   - 입력 이미지 x에 대해 노이즈 delta 생성
   - x_new = clamp(x + G(x))
   - 제약조건: delta의 최대 크기는 epsilon 이하

2. **Frozen DETR (D_det)**
   - x_new를 입력받아 특징맵 f와 예측값 y_pred 출력
   - f, y_pred = D_det(x_new)
   - 가중치 고정 (학습되지 않음)

3. **Gender Discriminator (D)**
   - DETR 특징맵 f에서 성별 예측
   - logits = D(f)

---

## 2. Loss Function 상세 (구체적 설명 및 예시)

### A. Discriminator Loss (L_D)
**목표**: 입력된 이미지가 남성인지 여성인지 **정확하게 맞추는 것**입니다.

**수식 개념**:
`L_D = CrossEntropy(예측값, 실제성별)`

**예시 상황**:
- **입력**: 여성 이미지 (Label: 1)
- **판별기 예측**: "여성일 확률 0.2" (틀림)
- **결과**: Loss가 매우 커짐 -> 판별기는 "여성일 확률"을 높이는 방향으로 학습합니다.
- **이상적 상태**: 여성 이미지면 "여성 확률 0.99", 남성 이미지면 "남성 확률 0.99"를 출력하게 됩니다.

---

### B. Generator Loss (L_G)
**목표**: 판별기를 속이면서(Fairness), 객체 검출 성능은 유지하고(Detection), 여성의 검출 점수를 남성 수준으로 올리는 것(Wasserstein)입니다.

`L_G = (lambda_fair * L_fair) + (beta * L_det) + (lambda_w * L_W)`

#### 1. Fairness Loss (L_fair)
**목표**: 판별기가 성별을 구분하지 못하게 만듭니다. (Adversarial + Entropy)

**수식 개념**:
`L_fair = - ( CE(예측값, 실제성별) + alpha * Entropy(예측값) )`

**예시 상황**:
- **입력**: 여성 이미지
- **판별기 예측**: "여성일 확률 0.9" (잘 맞춤)
- **Generator의 대응**:
    1.  **Adversarial**: CE Loss를 최대화하려고 함 -> 판별기가 틀리게 유도.
    2.  **Entropy**: 예측 확률 분포를 평평하게 만듦 -> "여성 0.5, 남성 0.5" 처럼 헷갈리게 유도.
- **결과**: 이미지를 아주 살짝 변형해서 판별기가 "어? 이거 남자인가? 여자인가? 모르겠는데(0.5)"라고 하게 만듭니다.

#### 2. Detection Loss (L_det)
**목표**: 이미지를 변형하더라도 원래 찾아야 할 객체(사람, 차 등)는 정확히 찾아야 합니다.

**수식 개념**:
`L_det = DETR_Loss(변형된 이미지의 예측박스, 정답박스)`

**예시 상황**:
- **상황**: 성별을 숨기려고 이미지에 노이즈를 넣었는데, 갑자기 사람이 사라지거나 엉뚱한 곳에 박스를 침.
- **결과**: L_det가 커짐 -> "성별은 숨기더라도 사람은 그 자리에 그대로 있다고 해야 해!"라고 학습.

#### 3. Wasserstein Alignment Loss (L_W) - **[4th 핵심]**
**목표**: **"여성 객체가 남성 객체만큼 잘 검출되게 하자"** (단, 남성 성능을 깎아내리진 말자)

**수식 개념**:
`L_W = 평균( ReLU( 남성점수 - 여성점수 ) )`

**구체적 예시 (점수 비교)**:
배치 내에서 가장 잘 검출된 남성 객체 점수(S_m)와 여성 객체 점수(S_f)를 크기순으로 나열해서 비교합니다.

*   **Case 1: 남성이 더 잘 검출될 때 (Gap 존재)**
    *   남성 점수: 0.9
    *   여성 점수: 0.7
    *   계산: `ReLU(0.9 - 0.7) = 0.2`
    *   **해석**: "여성 점수가 0.2만큼 부족해! 여성 점수를 올려!" -> **Loss 발생 (학습됨)**

*   **Case 2: 여성이 더 잘 검출될 때 (Gap 역전)**
    *   남성 점수: 0.8
    *   여성 점수: 0.9
    *   계산: `ReLU(0.8 - 0.9) = ReLU(-0.1) = 0`
    *   **해석**: "여성이 이미 남성보다 잘 나오네? 굳이 건들지 마." -> **Loss 0 (학습 안 함)**
    *   **중요**: 3rd 버전(양방향)에서는 이 경우에도 차이를 줄이려고 여성 점수를 0.8로 낮추거나 남성을 0.9로 올리려 했지만, **4th 버전은 여성 점수가 높으면 그냥 둡니다.**

**결론**: 이 Loss 덕분에 남성 성능은 그대로 유지되면서, 성능이 낮은 여성 객체들만 선택적으로 성능이 향상됩니다.

### 4. 심화: 어떻게 점수를 올리는가? (수학적 원리)

**"객체 점수(Score)"란?**
DETR 모델이 "이 박스 안에 객체가 있을 확률" (0.0 ~ 1.0)입니다.
- 점수 0.9: "여기 확실히 객체가 있어!"
- 점수 0.1: "여기 객체가 없을 수도 있어."

**학습 진행 과정 (Backpropagation)**:
우리의 목표는 `L_W = ReLU(0.9 - S_f)`를 **0으로 만드는 것**입니다. (남성점수 0.9 가정)

1.  **기울기(Gradient) 계산**:
    - 수식 `0.9 - S_f`를 줄이려면, **S_f(여성점수)가 커져야 합니다.**
    - 수학적으로 미분하면 S_f를 증가시키는 방향으로 신호가 생성됩니다.

2.  **Generator의 역할**:
    - 이 신호("점수 올려!")는 역전파를 타고 Generator에게 전달됩니다.
    - Generator는 **"내가 만든 노이즈가 여성 이미지를 DETR이 잘 알아보게 만들지 못했구나"**라고 판단합니다.

3.  **이미지 수정 (Action)**:
    - Generator는 여성 이미지의 픽셀을 미세하게 조정하여 **DETR이 "어? 여기 객체가 더 확실히 있네!"라고 느끼도록** 만듭니다.
    - 예: 객체의 테두리를 선명하게 하거나, 특징을 강조함.

4.  **결과**:
    - 수정된 이미지가 다시 DETR에 들어가면 점수가 0.7 -> 0.75 -> 0.8 ... 로 상승합니다.
    - 결국 남성 점수(0.9) 수준에 도달하면 Loss가 0이 되어 학습이 멈춥니다.
    - **남성 점수는 `detach` 되어 있어 변하지 않고 기준점 역할만 합니다.**
