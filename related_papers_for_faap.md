# FAAP ì—°êµ¬ì— ì ìš© ê°€ëŠ¥í•œ ë…¼ë¬¸ ëª¨ìŒ

## í˜„ì¬ ì—°êµ¬ íŠ¹ì„±
- **íƒœìŠ¤í¬**: Object Detectionì—ì„œì˜ Gender Fairness
- **ë°©ë²•**: Perturbation Generator + Cross-gender InfoNCE
- **Backbone**: DETR (frozen)
- **í•µì‹¬ ì•„ì´ë””ì–´**: ì„±ë³„ ê°„ featureë¥¼ ê°€ê¹ê²Œ, ê°™ì€ ì„±ë³„ ê°„ featureë¥¼ ë©€ê²Œ

---

## 1. Fair Contrastive Learning (í•µì‹¬ ê´€ë ¨)

### 1.1 FSCL: Fair Contrastive Learning for Facial Attribute Classification
- **í•™íšŒ**: CVPR 2022
- **ì €ì**: Sungho Park, Jewook Lee, Pilhyeon Lee, Sunhee Hwang, Dohyung Kim, Hyeran Byun
- **í•µì‹¬ ì•„ì´ë””ì–´**:
  - Fair Supervised Contrastive Loss (FSCL): SupConì— fairness penalty ì¶”ê°€
  - Group-wise Normalization: ê·¸ë£¹ ê°„ intra-class compactness ë¶ˆê· í˜• í•´ì†Œ
  - Equalized Odds: 30.5 â†’ 6.5 ê°œì„ 
- **ì ìš© ê°€ëŠ¥ì„±**: Group-wise Normalization ê°œë… ì°¸ê³  ê°€ëŠ¥
- **ë§í¬**: [Paper](https://openaccess.thecvf.com/content/CVPR2022/html/Park_Fair_Contrastive_Learning_for_Facial_Attribute_Classification_CVPR_2022_paper.html) | [GitHub](https://github.com/sungho-CoolG/FSCL) | [arXiv](https://arxiv.org/abs/2203.16209)

### 1.2 SupCon: Supervised Contrastive Learning
- **í•™íšŒ**: NeurIPS 2020
- **ì €ì**: Prannay Khosla et al. (Google Research)
- **í•µì‹¬ ì•„ì´ë””ì–´**:
  - ê°™ì€ í´ë˜ìŠ¤ ìƒ˜í”Œì„ positiveë¡œ ì‚¬ìš©í•˜ëŠ” supervised contrastive loss
  - Cross-entropy ëŒ€ë¹„ robustness ë° ì •í™•ë„ í–¥ìƒ
  - ImageNet ResNet-200ì—ì„œ 81.4% top-1 accuracy
- **ì ìš© ê°€ëŠ¥ì„±**: í˜„ì¬ InfoNCE êµ¬í˜„ì˜ ê¸°ë°˜ ì´ë¡ 
- **ë§í¬**: [Paper](https://proceedings.neurips.cc/paper/2020/hash/d89a66c7c80a29b1bdbab0f2a1a94af8-Abstract.html) | [arXiv](https://arxiv.org/abs/2004.11362)

### 1.3 FALCON: Fairness Learning via Contrastive Attention
- **í•™íšŒ**: CVPR 2025
- **ì €ì**: Thanh-Dat Truong, Utsav Prabhu, Bhiksha Raj, Jackson Cothren, Khoa Luu
- **í•µì‹¬ ì•„ì´ë””ì–´**: Continual semantic segmentationì—ì„œ contrastive attentionì„ í†µí•œ fairness
- **ì ìš© ê°€ëŠ¥ì„±**: Attention ê¸°ë°˜ fairness í•™ìŠµ ê¸°ë²• ì°¸ê³ 
- **ë§í¬**: [Paper](https://openaccess.thecvf.com/content/CVPR2025/papers/Truong_FALCON_Fairness_Learning_via_Contrastive_Attention_Approach_to_Continual_Semantic_CVPR_2025_paper.pdf)

---

## 2. Adversarial Perturbation for Fairness (ì§ì ‘ ê´€ë ¨)

### 2.1 FAAP: Fairness-Aware Adversarial Perturbation
- **í•™íšŒ**: CVPR 2022
- **ì €ì**: Wang et al.
- **í•µì‹¬ ì•„ì´ë””ì–´**:
  - ë°°í¬ëœ ëª¨ë¸ì„ ìˆ˜ì •í•˜ì§€ ì•Šê³  ì…ë ¥ perturbationìœ¼ë¡œ fairness ë‹¬ì„±
  - Gender, ethnicity ë“± ë¯¼ê°í•œ ì†ì„±ì— ëŒ€í•´ ëª¨ë¸ì„ "blind"í•˜ê²Œ í•¨
- **ì ìš© ê°€ëŠ¥ì„±**: **í˜„ì¬ ì—°êµ¬ì™€ ì§ì ‘ ê´€ë ¨** - ë™ì¼í•œ perturbation ê¸°ë°˜ ì ‘ê·¼
- **ë§í¬**: [Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Fairness-Aware_Adversarial_Perturbation_Towards_Bias_Mitigation_for_Deployed_Deep_Models_CVPR_2022_paper.pdf) | [arXiv](https://arxiv.org/abs/2203.01584)

### 2.2 Adversarial Debiasing (Mitigating Unwanted Biases)
- **í•™íšŒ**: AIES 2018
- **í•µì‹¬ ì•„ì´ë””ì–´**:
  - Classifierì™€ adversaryë¥¼ ë™ì‹œì— í•™ìŠµ
  - Adversaryê°€ bias í™œìš©ì„ ì‹œë„í•˜ê³ , classifierê°€ ì´ë¥¼ ì–µì œ
- **ì ìš© ê°€ëŠ¥ì„±**: Adversarial learning í”„ë ˆì„ì›Œí¬ ì°¸ê³ 
- **ë§í¬**: [Paper](https://dl.acm.org/doi/pdf/10.1145/3278721.3278779)

### 2.3 ALFA: Adversarial Latent Feature Augmentation for Fairness
- **í•µì‹¬ ì•„ì´ë””ì–´**:
  - Adversarial attackê³¼ data augmentationì„ latent spaceì—ì„œ ê²°í•©
  - Hyperplane rotationì„ í†µí•œ fairness í–¥ìƒ
- **ì ìš© ê°€ëŠ¥ì„±**: Latent spaceì—ì„œì˜ fairness augmentation
- **ë§í¬**: [OpenReview](https://openreview.net/forum?id=eFS9Pm7bsM)

### 2.4 Intra-Processing Methods for Debiasing Neural Networks
- **í•™íšŒ**: NeurIPS 2020
- **í•µì‹¬ ì•„ì´ë””ì–´**:
  - Random perturbation, adversarial fine-tuning, layer-wise optimization
  - ëª¨ë¸ ì¬í›ˆë ¨ ì—†ì´ fine-tuningìœ¼ë¡œ debiasing
- **ì ìš© ê°€ëŠ¥ì„±**: Fine-tuning ê¸°ë°˜ debiasing ê¸°ë²•
- **ë§í¬**: [Paper](https://proceedings.neurips.cc/paper/2020/file/1d8d70dddf147d2d92a634817f01b239-Paper.pdf) | [arXiv](https://arxiv.org/abs/2006.08564)

---

## 3. Object Detection Fairness (íƒœìŠ¤í¬ ê´€ë ¨)

### 3.1 Fairness in Autonomous Driving: Object Detection under Challenging Weather
- **ì €ì**: 2024
- **í•µì‹¬ ì•„ì´ë””ì–´**:
  - DETR (ResNet-50)ë¥¼ ì‚¬ìš©í•œ pedestrian detection fairness ë¶„ì„
  - ì–´ë‘ìš´ í™˜ê²½ì—ì„œ ì–´ë‘ìš´ í”¼ë¶€í†¤ì˜ ì„±ëŠ¥ ì €í•˜ í™•ì¸
  - Transformer attentionì´ í”¼ë¶€ íŒ¨ì¹˜ë³´ë‹¤ ì „ì²´ ì‚¬ëŒì„ ë´„
- **ì ìš© ê°€ëŠ¥ì„±**: **DETR ê¸°ë°˜ fairness ë¶„ì„ì˜ ì§ì ‘ì  ì°¸ê³ **
- **ë§í¬**: [arXiv](https://arxiv.org/abs/2406.00219)

### 3.2 Beyond Overall Accuracy: Pose- and Occlusion-driven Fairness in Pedestrian Detection
- **í•µì‹¬ ì•„ì´ë””ì–´**:
  - Pose(ë‹¤ë¦¬ ìƒíƒœ, íŒ”ê¿ˆì¹˜, ëª¸ ë°©í–¥)ì™€ occlusionì— ë”°ë¥¸ detection bias ë¶„ì„
  - Lateral view, parallel legsì—ì„œ bias ë°œê²¬
- **ì ìš© ê°€ëŠ¥ì„±**: Detectionì—ì„œì˜ fairness í‰ê°€ ê¸°ì¤€ ì°¸ê³ 
- **ë§í¬**: [arXiv](https://arxiv.org/abs/2509.26166)

### 3.3 Predictive Inequity in Object Detection
- **í•µì‹¬ ì•„ì´ë””ì–´**:
  - BDD100Kì— Fitzpatrick skin tone ì£¼ì„ ì¶”ê°€
  - Light skinì´ dark skinë³´ë‹¤ ì¼ê´€ë˜ê²Œ ë†’ì€ AP
  - ì‹œê°„ëŒ€ë‚˜ occlusionìœ¼ë¡œ ì„¤ëª…ë˜ì§€ ì•ŠëŠ” disparity
- **ì ìš© ê°€ëŠ¥ì„±**: **Object detectionì—ì„œì˜ demographic bias ë¶„ì„ ì°¸ê³ **
- **ë§í¬**: [arXiv](https://arxiv.org/abs/1902.11097)

### 3.4 FairMOT: Fairness of Detection and Re-ID in Multi-Object Tracking
- **í•™íšŒ**: IJCV 2021
- **í•µì‹¬ ì•„ì´ë””ì–´**:
  - Detectionê³¼ Re-ID ê°„ì˜ "fairness" (task balance)
  - Anchor-free detection (CenterNet) ê¸°ë°˜
  - ë‘ taskì— ë™ë“±í•œ ë¹„ì¤‘ ë¶€ì—¬
- **ì ìš© ê°€ëŠ¥ì„±**: Multi-task learningì—ì„œì˜ balance ì°¸ê³ 
- **ë§í¬**: [Paper](https://link.springer.com/article/10.1007/s11263-021-01513-4) | [GitHub](https://github.com/ifzhang/FairMOT) | [arXiv](https://arxiv.org/abs/2004.01888)

---

## 4. Feature Disentanglement for Fairness

### 4.1 FarconVAE: Learning Fair Representation via Distributional Contrastive Disentanglement
- **í•µì‹¬ ì•„ì´ë””ì–´**:
  - Non-sensitive representationê³¼ sensitive representation ë¶„ë¦¬
  - Swap-recon: ë‹¤ë¥¸ ìƒ˜í”Œì˜ non-sensitive representationìœ¼ë¡œ êµì²´ í›„ ì¬êµ¬ì„±
  - Fairnessì™€ domain generalization ëª¨ë‘ì— íš¨ê³¼ì 
- **ì ìš© ê°€ëŠ¥ì„±**: **Disentanglement + Contrastiveì˜ ê²°í•© ê¸°ë²•**
- **ë§í¬**: [arXiv](https://arxiv.org/abs/2206.08743)

### 4.2 FairSAD: Fair Graph Representation via Sensitive Attribute Disentanglement
- **í•™íšŒ**: ACM Web Conference 2024
- **í•µì‹¬ ì•„ì´ë””ì–´**:
  - Sensitive attributeë¥¼ ë…ë¦½ componentë¡œ ë¶„ë¦¬
  - Maskingì„ í†µí•´ fairness ë‹¬ì„±
- **ì ìš© ê°€ëŠ¥ì„±**: Attribute disentanglement ê¸°ë²•
- **ë§í¬**: [Paper](https://dl.acm.org/doi/10.1145/3589334.3645532) | [GitHub](https://github.com/zzoomd/fairsad) | [arXiv](https://arxiv.org/abs/2405.07011)

### 4.3 FFVAE: Flexibly Fair Representation Learning by Disentanglement
- **í•µì‹¬ ì•„ì´ë””ì–´**:
  - Multi-attribute fair representation learning
  - Sensitive attributesë¥¼ labelë¡œ ì‚¬ìš©í•˜ì—¬ factorized latent structure ìœ ë„
- **ì ìš© ê°€ëŠ¥ì„±**: VAE ê¸°ë°˜ fair disentanglement
- **ë§í¬**: [arXiv](https://arxiv.org/pdf/1906.02589)

### 4.4 DAB-GNN: Disentangling, Amplifying, and Debiasing
- **í•µì‹¬ ì•„ì´ë””ì–´**:
  - Attribute bias, structure bias, potential biasë¡œ 3-way ë¶„ë¦¬
  - Bias Contrast Optimizer (BCO)ì™€ Fairness Harmonizer (FH) ì‚¬ìš©
- **ì ìš© ê°€ëŠ¥ì„±**: Multi-source bias disentanglement
- **ë§í¬**: [arXiv](https://arxiv.org/abs/2408.12875)

---

## 5. Wasserstein Distance for Fairness (í˜„ì¬ ì‚¬ìš© ì¤‘)

### 5.1 Wasserstein-based Fairness Interpretability Framework
- **í•™íšŒ**: Machine Learning (Springer) 2022
- **í•µì‹¬ ì•„ì´ë””ì–´**:
  - Wasserstein metricìœ¼ë¡œ sub-population ê°„ model bias ì¸¡ì •
  - Transport theoryë¥¼ í†µí•œ bias decomposition ë° ì„¤ëª…
- **ì ìš© ê°€ëŠ¥ì„±**: **í˜„ì¬ Wasserstein lossì˜ ì´ë¡ ì  ë°°ê²½**
- **ë§í¬**: [Paper](https://link.springer.com/article/10.1007/s10994-022-06213-9) | [arXiv](https://arxiv.org/abs/2011.03156)

### 5.2 FairWASP: Fast and Optimal Fair Wasserstein Pre-processing
- **í•µì‹¬ ì•„ì´ë””ì–´**:
  - ì›ë³¸ ë°ì´í„°ë¥¼ ìˆ˜ì •í•˜ì§€ ì•Šê³  sample-level weight í•™ìŠµ
  - Wasserstein distance ìµœì†Œí™”í•˜ë©´ì„œ demographic parity ë‹¬ì„±
- **ì ìš© ê°€ëŠ¥ì„±**: Wasserstein ê¸°ë°˜ pre-processing ê¸°ë²•
- **ë§í¬**: [arXiv](https://arxiv.org/abs/2311.00109)

### 5.3 Distributionally Fair Stochastic Optimization using Wasserstein Distance
- **í•µì‹¬ ì•„ì´ë””ì–´**:
  - Wasserstein distanceë¥¼ ì‚¬ìš©í•œ distributional fairness ìµœì í™”
  - Support mismatchì—ì„œë„ ì˜ë¯¸ ìˆëŠ” metric
- **ì ìš© ê°€ëŠ¥ì„±**: Optimization ê´€ì ì˜ Wasserstein fairness
- **ë§í¬**: [Paper](https://optimization-online.org/wp-content/uploads/2024/02/Distributional_Fairness_Project_OPT.pdf)

---

## 6. Normalization for Fairness

### 6.1 FairAdaBN: Adaptive Batch Normalization for Fairness
- **í•µì‹¬ ì•„ì´ë””ì–´**:
  - Batch Normalizationì„ sensitive attributeì— adaptiveí•˜ê²Œ
  - ê° subgroupì— ëŒ€í•´ ë³„ë„ì˜ normalization block
  - Feature map alignmentë¥¼ í†µí•œ unfairness ì™„í™”
- **ì ìš© ê°€ëŠ¥ì„±**: **Group-wise normalizationì˜ ì‹¤ìš©ì  êµ¬í˜„**
- **ë§í¬**: [arXiv](https://arxiv.org/abs/2303.08325)

### 6.2 Group Normalization
- **í•™íšŒ**: ECCV 2018
- **ì €ì**: Yuxin Wu, Kaiming He (FAIR)
- **í•µì‹¬ ì•„ì´ë””ì–´**:
  - Batch sizeì— ë…ë¦½ì ì¸ normalization
  - Channelì„ ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì •ê·œí™”
- **ì ìš© ê°€ëŠ¥ì„±**: Small batchì—ì„œì˜ normalization ê¸°ë²•
- **ë§í¬**: [Paper](https://arxiv.org/abs/1803.08494)

---

## 7. Hard Negative Mining & Sampling Strategies

### 7.1 SCHaNe: Supervised Contrastive Learning with Hard Negative Samples
- **í•µì‹¬ ì•„ì´ë””ì–´**:
  - Fine-tuning ë‹¨ê³„ì—ì„œ hard negative sampling
  - Negativeë¥¼ positiveì™€ì˜ dissimilarityë¡œ weighting
  - ImageNet-1kì—ì„œ 86.14% accuracy SOTA
- **ì ìš© ê°€ëŠ¥ì„±**: **í˜„ì¬ InfoNCEì— hard negative mining ì¶”ê°€ ê°€ëŠ¥**
- **ë§í¬**: [arXiv](https://arxiv.org/abs/2209.00078)

### 7.2 Curriculum Learning for Hard Negative Mining
- **í•µì‹¬ ì•„ì´ë””ì–´**:
  - Easy-to-hard ìˆœì„œë¡œ negative í•™ìŠµ
  - False negativeì— ëŒ€í•œ regularization
  - ìˆ˜ë ´ ì†ë„ í–¥ìƒ
- **ì ìš© ê°€ëŠ¥ì„±**: Curriculum learning ê¸°ë°˜ negative mining
- **ë§í¬**: [ScienceDirect](https://www.sciencedirect.com/science/article/abs/pii/S002002552400447X)

### 7.3 X-Sample Contrastive Loss
- **í•™íšŒ**: 2024
- **í•µì‹¬ ì•„ì´ë””ì–´**:
  - InfoNCEì— soft cross-sample similarity ì¶”ê°€
  - Multiple positives ì§€ì›
  - Soft targetsë¥¼ ì‚¬ìš©í•œ distillation
- **ì ìš© ê°€ëŠ¥ì„±**: InfoNCE í™•ì¥ ê¸°ë²•
- **ë§í¬**: [arXiv](https://arxiv.org/abs/2407.18134)

---

## 8. Domain Adaptation & Cross-Domain Learning

### 8.1 CDCL: Cross-domain Contrastive Learning for UDA
- **í•µì‹¬ ì•„ì´ë””ì–´**:
  - Contrastive learningìœ¼ë¡œ domain discrepancy ê°ì†Œ
  - Domain-invariant feature alignment
- **ì ìš© ê°€ëŠ¥ì„±**: Cross-genderë¥¼ cross-domainì²˜ëŸ¼ ì·¨ê¸‰
- **ë§í¬**: [arXiv](https://arxiv.org/abs/2106.05528)

### 8.2 Multi-Source Domain Adaptation via Supervised Contrastive Learning
- **í•™íšŒ**: BMVC 2021
- **í•µì‹¬ ì•„ì´ë””ì–´**:
  - SCLì´ ìì—°ìŠ¤ëŸ½ê²Œ domain-invariant feature í•™ìŠµ
  - ê°™ì€ í´ë˜ìŠ¤ë¥¼ ë‹¹ê¸°ê³  ë‹¤ë¥¸ í´ë˜ìŠ¤ë¥¼ ë°€ë©´ì„œ domain alignment
- **ì ìš© ê°€ëŠ¥ì„±**: Multi-source fairness learning
- **ë§í¬**: [Paper](https://www.bmvc2021-virtualconference.com/assets/papers/0699.pdf)

---

## 9. Datasets & Benchmarks

### 9.1 BDD100K with Demographic Annotations
- 100K+ driving videos, skin tone ì£¼ì„ ì¶”ê°€
- Light skin vs dark skin detection disparity ë¶„ì„
- **ë§í¬**: [BAIR Blog](https://bair.berkeley.edu/blog/2018/05/30/bdd/)

### 9.2 CelebA / UTKFace
- CelebA: 200K+ facial images, 40 attributes
- UTKFace: Age, gender, ethnicity labels
- **í•œê³„**: Race imbalance (White í¸í–¥)
- **ë§í¬**: [FairFace Paper](https://arxiv.org/pdf/1908.04913)

### 9.3 Attribute Annotation for Autonomous Driving Datasets
- **í•™íšŒ**: Journal of Big Data 2024
- **í•µì‹¬ ì•„ì´ë””ì–´**:
  - BDD100K, nuImagesì— age, sex, skin tone ì£¼ì„
  - 90K+ people, 50K+ vehicles ì£¼ì„
  - ì•„ë™ ë¯¸ê²€ì¶œë¥ ì´ ì„±ì¸ë³´ë‹¤ 20.14% ë†’ìŒ
- **ì ìš© ê°€ëŠ¥ì„±**: **Fairness í‰ê°€ ë°ì´í„°ì…‹ ë° ê¸°ì¤€**
- **ë§í¬**: [Paper](https://link.springer.com/article/10.1186/s40537-024-00976-9)

---

## 10. Surveys & Comprehensive Reviews

### 10.1 Fairness and Bias Mitigation in Computer Vision: A Survey
- **ì—°ë„**: 2024
- **í•µì‹¬ ë‚´ìš©**:
  - Pre-processing, in-processing, post-processing ë¶„ë¥˜
  - Distributional methods, algorithmic approaches ì •ë¦¬
- **ë§í¬**: [arXiv](https://arxiv.org/abs/2408.02464)

### 10.2 Gender Bias in NLP and Computer Vision: A Comparative Survey
- **í•™íšŒ**: ACM Computing Surveys
- **í•µì‹¬ ë‚´ìš©**:
  - NLP, CV, visual-linguistic ëª¨ë¸ì˜ gender bias
  - ë°©ë²•ë¡ ì˜ cross-disciplinary ì ìš©
- **ë§í¬**: [Paper](https://dl.acm.org/doi/10.1145/3700438)

### 10.3 Racial Bias within Face Recognition: A Survey
- **í•™íšŒ**: ACM Computing Surveys
- **í•µì‹¬ ë‚´ìš©**: Face recognitionì—ì„œì˜ racial bias ì¢…í•© ì •ë¦¬
- **ë§í¬**: [Paper](https://dl.acm.org/doi/10.1145/3705295)

---

## ì ìš© ìš°ì„ ìˆœìœ„ ì¶”ì²œ

### ğŸ”´ ë†’ì€ ìš°ì„ ìˆœìœ„ (ì§ì ‘ ì ìš© ê°€ëŠ¥)
1. **SCHaNe** - Hard negative mining ì¶”ê°€
2. **FairAdaBN** - Group-wise normalization
3. **FAAP (CVPR 2022)** - ë™ì¼ íŒ¨ëŸ¬ë‹¤ì„ ë¹„êµ

### ğŸŸ¡ ì¤‘ê°„ ìš°ì„ ìˆœìœ„ (ì•„ì´ë””ì–´ ì°¸ê³ )
4. **FarconVAE** - Disentanglement + Contrastive
5. **Curriculum Hard Negative Mining** - í•™ìŠµ ì•ˆì •ì„±
6. **Wasserstein Fairness Framework** - ì´ë¡ ì  ë³´ê°•

### ğŸŸ¢ ë‚®ì€ ìš°ì„ ìˆœìœ„ (ì°¸ê³ ìš©)
7. **FSCL** - Classificationìš©ì´ì§€ë§Œ normalization ì°¸ê³ 
8. **FairMOT** - Multi-task balance ì°¸ê³ 
9. **Domain Adaptation** - Cross-genderë¥¼ cross-domainìœ¼ë¡œ í•´ì„

---

## í˜„ì¬ ì—°êµ¬ì™€ì˜ ë¹„êµí‘œ

| ë…¼ë¬¸ | íƒœìŠ¤í¬ | Backbone | í•™ìŠµ ëŒ€ìƒ | Contrastive ë°©ì‹ |
|------|--------|----------|-----------|------------------|
| **FAAP (í˜„ì¬)** | Detection | DETR (frozen) | Generator | Cross-gender positive |
| FSCL | Classification | ResNet | Encoder | Same-class positive |
| FAAP (CVPR22) | Classification | Various (frozen) | Perturbation | Adversarial |
| FarconVAE | Various | VAE | Encoder | Disentanglement |
| SCHaNe | Classification | ResNet | Encoder | Hard negative |

---

## 11. ğŸ¯ í˜„ì¬ ì—°êµ¬ì— êµ¬ì²´ì  ì ìš© ë°©ë²•

### 11.1 Hard Negative Mining (SCHaNe) - **ìµœìš°ì„  ì¶”ì²œ**

**í˜„ì¬ ë¬¸ì œì **: ëª¨ë“  same-gender ìƒ˜í”Œì„ ë™ì¼í•œ ê°€ì¤‘ì¹˜ë¡œ negative ì²˜ë¦¬

**ì ìš© ë°©ë²•**: Hard negativeì— ë” ë†’ì€ ê°€ì¤‘ì¹˜ ë¶€ì—¬

```python
class CrossGenderInfoNCELossWithHardNegative(nn.Module):
    """
    SCHaNe ìŠ¤íƒ€ì¼ hard negative mining ì ìš©
    """
    def __init__(self, temperature=0.07, beta=0.5):
        super().__init__()
        self.temperature = temperature
        self.beta = beta  # hard negative ê°•ë„ ì¡°ì ˆ

    def forward(self, proj_f, proj_m):
        # ê¸°ì¡´ similarity ê³„ì‚°
        sim_f2m = torch.mm(proj_f, proj_m.t()) / self.temperature  # positive
        sim_f2f = torch.mm(proj_f, proj_f.t()) / self.temperature  # negative

        # Hard negative weighting: similarityê°€ ë†’ì€ negativeì— ë” ë†’ì€ ê°€ì¤‘ì¹˜
        # (positiveì™€ í—·ê°ˆë¦¬ê¸° ì‰¬ìš´ negativeê°€ hard negative)
        neg_weights = torch.exp(self.beta * sim_f2f)  # hard negative ê°•ì¡°
        neg_weights = neg_weights / neg_weights.sum(dim=1, keepdim=True)  # normalize

        # Weighted negative
        weighted_neg = (neg_weights * torch.exp(sim_f2f)).sum(dim=1)

        # InfoNCE with hard negative
        pos_exp = torch.exp(sim_f2m).sum(dim=1)
        loss = -torch.log(pos_exp / (pos_exp + weighted_neg)).mean()

        return loss
```

**ê¸°ëŒ€ íš¨ê³¼**:
- ì„±ë³„ ê°„ êµ¬ë¶„ì´ ì–´ë ¤ìš´ ìƒ˜í”Œì— ì§‘ì¤‘ â†’ ë” robustí•œ fairness
- ìˆ˜ë ´ ì†ë„ í–¥ìƒ

---

### 11.2 Group-wise Feature Normalization (FSCL/FairAdaBN) - **ë†’ì€ ìš°ì„ ìˆœìœ„**

**í˜„ì¬ ë¬¸ì œì **: ì—¬ì„±/ë‚¨ì„± ê·¸ë£¹ ê°„ feature ë¶„í¬ ë¶ˆê· í˜• ê°€ëŠ¥

**ì ìš© ë°©ë²•**: Projection ì „ ì„±ë³„ë³„ normalization

```python
class GenderAwareProjectionHead(nn.Module):
    """
    FairAdaBN ìŠ¤íƒ€ì¼: ì„±ë³„ë³„ ë³„ë„ì˜ normalization
    """
    def __init__(self, input_dim=256, hidden_dim=256, output_dim=128):
        super().__init__()
        # ì„±ë³„ë³„ ë³„ë„ì˜ BatchNorm
        self.bn_female = nn.BatchNorm1d(input_dim)
        self.bn_male = nn.BatchNorm1d(input_dim)

        # ê³µìœ  projection layers
        self.net = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(inplace=True),
            nn.Linear(hidden_dim, output_dim),
        )

    def forward(self, x, gender_mask):
        """
        x: (batch, num_queries, feature_dim)
        gender_mask: (batch,) - True for female, False for male
        """
        pooled = x.mean(dim=1)  # (batch, feature_dim)

        # ì„±ë³„ë³„ normalization
        normalized = torch.zeros_like(pooled)
        if gender_mask.any():
            normalized[gender_mask] = self.bn_female(pooled[gender_mask])
        if (~gender_mask).any():
            normalized[~gender_mask] = self.bn_male(pooled[~gender_mask])

        proj = self.net(normalized)
        return F.normalize(proj, dim=-1, p=2)
```

**ëŒ€ì•ˆ: Instance Normalization ë°©ì‹**
```python
class GroupWiseInstanceNorm(nn.Module):
    """
    FSCL ìŠ¤íƒ€ì¼: ê·¸ë£¹ ë‚´ ë¶„ì‚°ì„ ì •ê·œí™”í•˜ì—¬ ê·¸ë£¹ ê°„ compactness ê· í˜•
    """
    def forward(self, feat_f, feat_m):
        # ê° ê·¸ë£¹ ë‚´ì—ì„œ mean/std ì •ê·œí™”
        feat_f_norm = (feat_f - feat_f.mean(dim=0)) / (feat_f.std(dim=0) + 1e-6)
        feat_m_norm = (feat_m - feat_m.mean(dim=0)) / (feat_m.std(dim=0) + 1e-6)
        return feat_f_norm, feat_m_norm
```

**ê¸°ëŒ€ íš¨ê³¼**:
- ê·¸ë£¹ ê°„ feature ë¶„í¬ ì •ë ¬
- Intra-class compactness ê· í˜•

---

### 11.3 Curriculum Learning for Negatives - **ì¤‘ê°„ ìš°ì„ ìˆœìœ„**

**í˜„ì¬ ë¬¸ì œì **: í•™ìŠµ ì´ˆê¸°ì— ì–´ë ¤ìš´ negativeë¡œ ì¸í•œ ë¶ˆì•ˆì •

**ì ìš© ë°©ë²•**: Easy-to-hard negative curriculum

```python
class CurriculumInfoNCELoss(nn.Module):
    """
    í•™ìŠµ ì§„í–‰ì— ë”°ë¼ hard negative ë¹„ì¤‘ ì¦ê°€
    """
    def __init__(self, temperature=0.07):
        super().__init__()
        self.temperature = temperature

    def forward(self, proj_f, proj_m, epoch, total_epochs):
        # Curriculum: ì´ˆê¸°ì—ëŠ” ì‰¬ìš´ negative, í›„ê¸°ì—ëŠ” hard negative
        curriculum_beta = min(1.0, epoch / (total_epochs * 0.5))  # 50% ì§€ì ì—ì„œ ìµœëŒ€

        sim_f2m = torch.mm(proj_f, proj_m.t()) / self.temperature
        sim_f2f = torch.mm(proj_f, proj_f.t()) / self.temperature

        # ëŒ€ê°ì„  ë§ˆìŠ¤í‚¹
        mask = torch.eye(proj_f.size(0), device=proj_f.device, dtype=torch.bool)
        sim_f2f = sim_f2f.masked_fill(mask, float('-inf'))

        # Curriculum-based hard negative weighting
        if curriculum_beta > 0:
            neg_weights = F.softmax(curriculum_beta * sim_f2f, dim=1)
            weighted_neg_logsumexp = torch.log((neg_weights * torch.exp(sim_f2f)).sum(dim=1))
        else:
            weighted_neg_logsumexp = torch.logsumexp(sim_f2f, dim=1)

        pos_logsumexp = torch.logsumexp(sim_f2m, dim=1)
        all_logsumexp = torch.logsumexp(
            torch.stack([pos_logsumexp, weighted_neg_logsumexp], dim=1), dim=1
        )

        return -(pos_logsumexp - all_logsumexp).mean()
```

**ê¸°ëŒ€ íš¨ê³¼**:
- í•™ìŠµ ì´ˆê¸° ì•ˆì •ì„± í–¥ìƒ
- ì ì§„ì ìœ¼ë¡œ ì–´ë ¤ìš´ ì¼€ì´ìŠ¤ í•™ìŠµ

---

### 11.4 Feature Disentanglement (FarconVAE) - **ì¤‘ê°„ ìš°ì„ ìˆœìœ„**

**í˜„ì¬ ë¬¸ì œì **: Generatorê°€ ì„±ë³„ ì •ë³´ì™€ detection ì •ë³´ë¥¼ í•¨ê»˜ í•™ìŠµ

**ì ìš© ë°©ë²•**: Gender-invariantì™€ gender-specific feature ë¶„ë¦¬

```python
class DisentangledProjectionHead(nn.Module):
    """
    FarconVAE ìŠ¤íƒ€ì¼: sensitive/non-sensitive feature ë¶„ë¦¬
    """
    def __init__(self, input_dim=256, hidden_dim=256, output_dim=128):
        super().__init__()
        # Gender-invariant branch (fairnessìš©)
        self.invariant_head = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, output_dim),
        )
        # Gender-specific branch (disentanglement í™•ì¸ìš©)
        self.specific_head = nn.Sequential(
            nn.Linear(input_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(hidden_dim // 2, 2),  # binary gender classification
        )

    def forward(self, x):
        pooled = x.mean(dim=1)
        z_inv = F.normalize(self.invariant_head(pooled), dim=-1)
        z_spec = self.specific_head(pooled)
        return z_inv, z_spec


class DisentanglementLoss(nn.Module):
    """
    z_invê°€ ì„±ë³„ ì •ë³´ë¥¼ í¬í•¨í•˜ì§€ ì•Šë„ë¡ adversarial loss
    """
    def __init__(self, lambda_adv=0.1):
        super().__init__()
        self.lambda_adv = lambda_adv
        self.gender_classifier = nn.Sequential(
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 2),
        )

    def forward(self, z_inv, gender_labels):
        # Gradient reversal: z_invê°€ ì„±ë³„ ì˜ˆì¸¡ ëª»í•˜ê²Œ
        gender_pred = self.gender_classifier(z_inv)

        # Adversarial: ì„±ë³„ ì˜ˆì¸¡ ì •í™•ë„ë¥¼ ë‚®ì¶”ëŠ” ë°©í–¥
        ce_loss = F.cross_entropy(gender_pred, gender_labels)
        entropy = -(F.softmax(gender_pred, dim=1) * F.log_softmax(gender_pred, dim=1)).sum(dim=1).mean()

        # ì„±ë³„ ì˜ˆì¸¡ ì–´ë µê²Œ + ì—”íŠ¸ë¡œí”¼ ìµœëŒ€í™”
        return -ce_loss + self.lambda_adv * entropy
```

**ê¸°ëŒ€ íš¨ê³¼**:
- Detection featureì—ì„œ ì„±ë³„ ì •ë³´ ëª…ì‹œì  ì œê±°
- ë” interpretableí•œ ëª¨ë¸

---

### 11.5 Wasserstein Loss ê°œì„  - **ë‚®ì€ ìš°ì„ ìˆœìœ„ (ì´ë¯¸ êµ¬í˜„ë¨)**

**í˜„ì¬ êµ¬í˜„**: Score-level 1D Wasserstein (ë‹¨ë°©í–¥)

**ê°œì„  ë°©ë²•**: Feature-level Wasserstein ì¶”ê°€

```python
def sliced_wasserstein_distance(feat_f, feat_m, num_projections=50):
    """
    Feature-level Sliced Wasserstein Distance
    ê³ ì°¨ì› feature ë¶„í¬ ì •ë ¬ì— íš¨ê³¼ì 
    """
    dim = feat_f.size(1)

    # Random projections
    projections = torch.randn(num_projections, dim, device=feat_f.device)
    projections = F.normalize(projections, dim=1)

    # Project features
    proj_f = torch.mm(feat_f, projections.t())  # (N_f, num_proj)
    proj_m = torch.mm(feat_m, projections.t())  # (N_m, num_proj)

    # 1D Wasserstein for each projection
    total_dist = 0
    for i in range(num_projections):
        sorted_f = proj_f[:, i].sort().values
        sorted_m = proj_m[:, i].sort().values

        # Interpolate to same size
        k = max(len(sorted_f), len(sorted_m))
        sorted_f = _resize_sorted(sorted_f, k)
        sorted_m = _resize_sorted(sorted_m, k)

        total_dist += (sorted_f - sorted_m).abs().mean()

    return total_dist / num_projections
```

**ê¸°ëŒ€ íš¨ê³¼**:
- Score ì™¸ì— feature ë¶„í¬ë„ ì •ë ¬
- ë” ê·¼ë³¸ì ì¸ fairness ë‹¬ì„±

---

### 11.6 Multi-view Augmentation (SimCLR í™•ì¥) - **ë‚®ì€ ìš°ì„ ìˆœìœ„**

**í˜„ì¬ êµ¬í˜„**: Single augmentation (ColorJitter)

**ê°œì„  ë°©ë²•**: ë‘ ê°œì˜ ë‹¤ë¥¸ augmentation view ìƒì„±

```python
class DualViewSimCLRAugmentation(nn.Module):
    """
    SimCLR ì›ë³¸ ìŠ¤íƒ€ì¼: ê°™ì€ ì´ë¯¸ì§€ì—ì„œ ë‘ ê°œì˜ ë‹¤ë¥¸ view ìƒì„±
    """
    def __init__(self):
        super().__init__()
        self.aug1 = T.Compose([
            T.ColorJitter(0.4, 0.4, 0.4, 0.1),
            T.RandomGrayscale(p=0.2),
        ])
        self.aug2 = T.Compose([
            T.ColorJitter(0.3, 0.3, 0.3, 0.05),
            # GaussianBlurëŠ” detection ì„±ëŠ¥ ì €í•˜ ìš°ë ¤ë¡œ ì œì™¸
        ])

    def forward(self, x):
        # ... denormalize, apply aug, renormalize ...
        view1 = self._apply(x, self.aug1)
        view2 = self._apply(x, self.aug2)
        return view1, view2
```

**ì¶”ê°€ Loss**: ê°™ì€ ì´ë¯¸ì§€ì˜ ë‘ viewë„ positiveë¡œ ì²˜ë¦¬
```python
# Cross-gender InfoNCE + Self-consistency
loss_cross_gender = infonce_loss(proj_f, proj_m)
loss_self_view = self_consistency_loss(proj_f_v1, proj_f_v2)  # ê°™ì€ ì´ë¯¸ì§€ ë‘ view
total = loss_cross_gender + 0.5 * loss_self_view
```

---

## 12. ğŸ”¬ ì‹¤í—˜ ì„¤ê³„ ì œì•ˆ

### Phase 1: Baseline í™•ë¦½ (í˜„ì¬)
- `train_faap_simclr_infonce.py` ì‹¤í–‰
- AP Gap, AR Gap ì¸¡ì •

### Phase 2: Hard Negative Mining ì¶”ê°€
```bash
# ìƒˆ íŒŒì¼: train_faap_simclr_hard_negative.py
python train_faap_simclr_hard_negative.py --hard_neg_beta 0.5
```

### Phase 3: Group-wise Normalization ì¶”ê°€
```bash
# ìƒˆ íŒŒì¼: train_faap_simclr_groupnorm.py
python train_faap_simclr_groupnorm.py --use_group_norm
```

### Phase 4: ì¡°í•© ì‹¤í—˜
```bash
# Hard Negative + Group Norm
python train_faap_simclr_combined.py --hard_neg_beta 0.5 --use_group_norm
```

### í‰ê°€ ì§€í‘œ
| ì§€í‘œ | ëª©í‘œ | ì¸¡ì • ë°©ë²• |
|------|------|-----------|
| AP Gap (M-F) | < 0.09 | eval ìŠ¤í¬ë¦½íŠ¸ |
| AR Gap (M-F) | < 0.05 | eval ìŠ¤í¬ë¦½íŠ¸ |
| Female AP | > 0.41 | eval ìŠ¤í¬ë¦½íŠ¸ |
| Overall AP | â‰¥ baseline | ì„±ëŠ¥ ì €í•˜ ì—†ì–´ì•¼ í•¨ |

---

## 13. ğŸ“Š ì˜ˆìƒ íš¨ê³¼ ìš”ì•½

| ê¸°ë²• | êµ¬í˜„ ë‚œì´ë„ | ì˜ˆìƒ AP Gap ê°œì„  | ì£¼ì˜ì‚¬í•­ |
|------|-------------|------------------|----------|
| Hard Negative Mining | â­â­ | 10-15% | beta íŠœë‹ í•„ìš” |
| Group-wise Norm | â­â­ | 5-10% | batch size ì˜ì¡´ |
| Curriculum Learning | â­â­â­ | 5-10% | ìˆ˜ë ´ ì•ˆì •ì„± |
| Disentanglement | â­â­â­â­ | 10-20% | ì¶”ê°€ loss ë³µì¡ |
| Feature Wasserstein | â­â­â­ | 5-10% | ê³„ì‚°ëŸ‰ ì¦ê°€ |
| Dual-view Aug | â­â­ | 3-5% | ë©”ëª¨ë¦¬ 2ë°° |

---

## 14. ğŸš€ ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ ì½”ë“œ ë³€ê²½

### 14.1 `train_faap_simclr_infonce.py`ì— Hard Negative ì¶”ê°€

```python
# CrossGenderInfoNCELoss í´ë˜ìŠ¤ ìˆ˜ì •
def forward(self, proj_f, proj_m, hard_neg_beta=0.0):
    # ... ê¸°ì¡´ ì½”ë“œ ...

    # Hard negative weighting ì¶”ê°€
    if hard_neg_beta > 0:
        neg_weights_f = F.softmax(hard_neg_beta * sim_f2f, dim=1)
        sim_f2f_weighted = torch.log((neg_weights_f * torch.exp(sim_f2f)).sum(dim=1, keepdim=True))
    else:
        sim_f2f_weighted = sim_f2f

    # ... ë‚˜ë¨¸ì§€ ì½”ë“œ ...
```

### 14.2 argparseì— ì¶”ê°€í•  ì¸ì

```python
parser.add_argument("--hard_neg_beta", type=float, default=0.0,
                    help="Hard negative mining strength (0=off, 0.5=medium, 1.0=strong)")
parser.add_argument("--use_group_norm", action="store_true",
                    help="Use gender-wise normalization in projection head")
parser.add_argument("--curriculum", action="store_true",
                    help="Use curriculum learning for hard negatives")
```

---

*ìƒì„±ì¼: 2025-01-20*
*ëª©ì : FAAP ì—°êµ¬ì— ì ìš© ê°€ëŠ¥í•œ ê´€ë ¨ ë…¼ë¬¸ ìˆ˜ì§‘ ë° êµ¬ì²´ì  ì ìš© ë°©ë²•*
*ìµœì¢… ìˆ˜ì •: êµ¬ì²´ì  ì ìš© ë°©ë²• ë° ì½”ë“œ ì˜ˆì‹œ ì¶”ê°€*
