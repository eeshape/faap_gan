# FAAP: Gender-Aware Score-Based Contrastive Learning (3rd Version)

## Fair Adversarial Attack Perturbation을 통한 객체 탐지 공정성 향상

---

# 1. 연구 배경 및 동기

## 1.1 문제 상황: 객체 탐지의 성별 편향

현대 딥러닝 기반 객체 탐지 모델(DETR, Faster R-CNN 등)은 뛰어난 성능을 보이지만, **특정 인구통계학적 그룹에 대해 불공정한 성능 차이**를 보이는 문제가 있습니다.

### 실제 관측된 문제
```
┌────────────────────────────────────────────────────────┐
│              Baseline DETR 성능 (Person Detection)     │
├────────────────────────────────────────────────────────┤
│  전체 AP (Average Precision): 0.456                    │
│  남성 AP (Male):              0.511                    │
│  여성 AP (Female):            0.404                    │
│  ─────────────────────────────────────────────────     │
│  AP Gap (남성 - 여성):        0.107  ← 문제!           │
└────────────────────────────────────────────────────────┘
```

**이것이 의미하는 바:**
- 동일한 조건에서 여성이 포함된 이미지의 탐지 성능이 남성 대비 **10.7%p 낮음**
- 자율주행, 보안 시스템, 의료 영상 등에서 **안전 및 윤리적 문제** 야기 가능
- EU AI Act 등 규제에서 AI 공정성을 법적으로 요구하는 추세

## 1.2 기존 접근법의 한계

| 접근법 | 설명 | 한계 |
|--------|------|------|
| 데이터 리밸런싱 | 학습 데이터에서 성별 비율 조정 | 근본적 편향 해결 불가, 데이터 수집 비용 |
| 모델 재학습 | 공정성 제약 추가하여 재학습 | 기존 모델 수정 필요, 비용 큼 |
| Post-hoc 보정 | 출력 결과를 후처리로 조정 | 탐지 성능 저하, 임시방편 |

## 1.3 본 연구의 접근: FAAP (Fair Adversarial Attack Perturbation)

**핵심 아이디어:** 입력 이미지에 미세한 perturbation(섭동)을 추가하여, 기존 모델을 수정하지 않고도 공정한 탐지 결과를 유도

```
┌─────────────────────────────────────────────────────────────────┐
│                      FAAP 개념도                                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│   Original Image        Perturbation         Perturbed Image    │
│   ┌─────────────┐      ┌─────────────┐      ┌─────────────┐     │
│   │             │      │ ≈≈≈≈≈≈≈≈≈≈≈ │      │             │     │
│   │   👤 여성   │  +   │  (미세한    │  =   │   👤 여성   │     │
│   │             │      │   노이즈)   │      │  (더 잘     │     │
│   │             │      │             │      │   탐지됨)   │     │
│   └─────────────┘      └─────────────┘      └─────────────┘     │
│                                                                  │
│   • Perturbation은 사람 눈에 거의 보이지 않음 (ε ≤ 0.10)        │
│   • 기존 DETR 모델 변경 없이 적용 가능                           │
│   • 추론 시에만 perturbation 추가하면 됨                         │
└─────────────────────────────────────────────────────────────────┘
```

---

# 2. 이전 버전 분석 및 실패 원인

## 2.1 2nd 버전: Score-Based Contrastive Learning

### 2.1.1 2nd 버전의 가설
> "탐지 점수(Score)가 낮은 이미지의 feature를 점수가 높은 이미지 방향으로 당기면, 저성능 그룹의 탐지 성능이 향상될 것이다."

### 2.1.2 2nd 버전의 방법
```
분리 기준: Detection Score만 사용

Low-Score 그룹 ←────────────────→ High-Score 그룹
(Anchor/Negative)     당기기      (Positive)

문제: 성별 정보를 전혀 사용하지 않음
```

### 2.1.3 2nd 버전이 실패한 이유

**실험 관측 결과:**
```python
# 실제 배치에서의 Score 분포 (예시)
Female scores: [0.42, 0.38, 0.45, 0.41]  → 평균: 0.415
Male scores:   [0.44, 0.39, 0.43, 0.40]  → 평균: 0.415

# Score가 거의 동일함!
```

**문제 분석:**
```
┌─────────────────────────────────────────────────────────────────┐
│                  2nd 버전 실패 원인 분석                         │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│   가정: Score_Female << Score_Male (여성 점수가 현저히 낮음)     │
│   현실: Score_Female ≈ Score_Male (배치 내 점수 차이 미미)       │
│                                                                  │
│   ┌─────────────────────────────────────────────────────────┐   │
│   │     Score 기반 분리 결과                                 │   │
│   │                                                          │   │
│   │     Low-Score 그룹          High-Score 그룹              │   │
│   │     ┌───────────────┐       ┌───────────────┐            │   │
│   │     │ 👤F  👤M      │       │ 👤F  👤M      │            │   │
│   │     │ 👤M  👤F      │       │ 👤M  👤F      │            │   │
│   │     └───────────────┘       └───────────────┘            │   │
│   │                                                          │   │
│   │     → 양쪽 그룹에 남녀가 균등하게 섞임!                   │   │
│   │     → 성별 공정성 학습 효과 없음                         │   │
│   └─────────────────────────────────────────────────────────┘   │
│                                                                  │
│   결과: AP Gap 0.107 → 0.12+ (오히려 악화)                       │
└─────────────────────────────────────────────────────────────────┘
```

---

# 3. 제안 방법: Gender-Aware Score-Based Contrastive Learning (3rd)

## 3.1 핵심 아이디어

> **"성별 정보를 명시적으로 사용하여, 여성 이미지의 feature가 (잘 탐지되는) 남성 이미지의 feature 분포를 닮도록 학습한다."**

### 3.1.1 직관적 설명

```
┌─────────────────────────────────────────────────────────────────┐
│                    3rd 버전 핵심 개념                            │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│   Feature Space에서의 변화                                       │
│                                                                  │
│   [학습 전]                        [학습 후]                     │
│                                                                  │
│      M M                              M M                        │
│     M M M    ← 남성 feature          M M M                       │
│      M M        (탐지 잘 됨)         F M F                       │
│                                      M F M   ← 여성이 남성       │
│                                       F F       영역으로 이동    │
│      F F                                                         │
│     F F F    ← 여성 feature                                      │
│      F F        (탐지 안 됨)                                     │
│                                                                  │
│   목표: 여성 feature → 남성 feature 방향으로 당기기              │
│         (Contrastive Learning 활용)                              │
└─────────────────────────────────────────────────────────────────┘
```

### 3.1.2 왜 이것이 작동하는가?

1. **DETR의 특성**: DETR은 feature space에서 특정 패턴을 인식하여 객체를 탐지
2. **편향의 원인**: 남성 이미지의 feature가 탐지에 유리한 영역에 분포
3. **해결책**: 여성 이미지에 perturbation을 추가하여 feature를 유리한 영역으로 이동
4. **결과**: 동일한 DETR 모델이 여성도 잘 탐지하게 됨

## 3.2 Contrastive Learning 구조

### 3.2.1 역할 정의

| 역할 | 할당 | 직관적 설명 |
|------|------|-------------|
| **Anchor** | 여성 이미지 | "이 이미지의 feature를 개선하고 싶다" |
| **Positive** | 남성 이미지 | "이쪽 방향으로 당기고 싶다 (탐지 잘 되는 영역)" |
| **Negative** | 다른 여성 이미지 | "이쪽에서 멀어지고 싶다 (탐지 안 되는 영역)" |

### 3.2.2 학습 방향

```
┌─────────────────────────────────────────────────────────────────┐
│                  Contrastive Learning 동작                       │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│                        Positive (Male)                           │
│                             👤                                   │
│                              ↑                                   │
│                              │ 당기기 (Pull)                     │
│                              │                                   │
│        Negative ←───────── Anchor ─────────→ Negative           │
│        (Female)   밀어내기   👤     밀어내기   (Female)          │
│           👤       (Push)  (Female)  (Push)      👤              │
│                                                                  │
│   Loss가 최소화되면:                                             │
│   • Anchor-Positive 거리 ↓ (가까워짐)                            │
│   • Anchor-Negative 거리 ↑ (멀어짐)                              │
│                                                                  │
│   결과: 여성 feature가 남성 feature 영역으로 이동                │
└─────────────────────────────────────────────────────────────────┘
```

## 3.3 Adaptive Score Weighting (핵심 혁신)

### 3.3.1 동기

단순히 "여성→남성" 방향으로 당기는 것만으로는 부족합니다.
**탐지 점수 차이가 큰 쌍에 더 강한 학습 신호**를 주어야 합니다.

### 3.3.2 직관적 설명

```
┌─────────────────────────────────────────────────────────────────┐
│              Adaptive Weighting 개념                             │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│   Case 1: 여성(저점수) ↔ 남성(고점수) → 강하게 당기기           │
│   ┌─────────────────────────────────────────────────────────┐   │
│   │  Female (score: 0.3)  ════════════════▶  Male (score: 0.8) │   │
│   │                        강한 힘 (w=1.5)                    │   │
│   └─────────────────────────────────────────────────────────┘   │
│   "점수가 매우 낮은 여성은 점수가 높은 남성 방향으로 강하게"     │
│                                                                  │
│   Case 2: 여성(중점수) ↔ 남성(중점수) → 보통으로 당기기         │
│   ┌─────────────────────────────────────────────────────────┐   │
│   │  Female (score: 0.5)  ─────────────▶  Male (score: 0.6)   │   │
│   │                       보통 힘 (w=1.0)                     │   │
│   └─────────────────────────────────────────────────────────┘   │
│   "점수가 비슷하면 보통 강도로"                                  │
│                                                                  │
│   Case 3: 여성(고점수) ↔ 남성(저점수) → 약하게 당기기           │
│   ┌─────────────────────────────────────────────────────────┐   │
│   │  Female (score: 0.7)  ───▶  Male (score: 0.4)            │   │
│   │                     약한 힘 (w=0.5)                       │   │
│   └─────────────────────────────────────────────────────────┘   │
│   "이미 점수가 높은 여성은 굳이 강하게 당길 필요 없음"           │
└─────────────────────────────────────────────────────────────────┘
```

### 3.3.3 가중치 계산 수식

```
Score 차이:     Δs = score_male - score_female
정규화:         Δs_norm = sigmoid(Δs × 5)        → [0, 1] 범위
최종 가중치:    w = 0.5 + Δs_norm                → [0.5, 1.5] 범위
```

| score_male | score_female | Δs | w | 해석 |
|------------|--------------|-----|-----|------|
| 0.8 | 0.3 | +0.5 | ~1.5 | 강하게 당김 |
| 0.6 | 0.5 | +0.1 | ~1.0 | 보통 |
| 0.4 | 0.7 | -0.3 | ~0.5 | 약하게 당김 |

---

# 4. 수학적 정의

## 4.1 기호 정의

| 기호 | 정의 | 차원 |
|------|------|------|
| $z_f^{(i)}$ | i번째 여성 이미지의 projection feature | $(D,)$ |
| $z_m^{(j)}$ | j번째 남성 이미지의 projection feature | $(D,)$ |
| $s_f^{(i)}$ | i번째 여성 이미지의 detection score | scalar |
| $s_m^{(j)}$ | j번째 남성 이미지의 detection score | scalar |
| $\tau$ | Temperature (온도 파라미터) | scalar |
| $N_f$ | 배치 내 여성 이미지 수 | scalar |
| $N_m$ | 배치 내 남성 이미지 수 | scalar |

## 4.2 Similarity 계산

**Cosine Similarity (L2-normalized features 사용):**
$$
\text{sim}(z_a, z_b) = \frac{z_a \cdot z_b}{\|z_a\| \|z_b\|} = z_a \cdot z_b \quad (\text{이미 normalized})
$$

**Temperature-scaled Similarity:**
$$
s_{ij} = \frac{\text{sim}(z_f^{(i)}, z_m^{(j)})}{\tau}
$$

Temperature $\tau$의 역할:
- $\tau$ 작음 (0.07): 분포가 날카로움 → 가장 유사한 것에 집중
- $\tau$ 큼 (1.0): 분포가 부드러움 → 모든 샘플 균등 고려

## 4.3 Gender-Aware Contrastive Loss (InfoNCE 변형)

### 4.3.1 Female → Male 방향 Loss

$$
\mathcal{L}_{F \rightarrow M} = -\frac{1}{N_f} \sum_{i=1}^{N_f} \log \frac{\sum_{j=1}^{N_m} w_{ij} \cdot \exp(s_{ij}^{f \rightarrow m})}{\sum_{j=1}^{N_m} w_{ij} \cdot \exp(s_{ij}^{f \rightarrow m}) + \sum_{k \neq i}^{N_f} \exp(s_{ik}^{f \rightarrow f})}
$$

**각 항의 의미:**

```
분자: Σ w_ij · exp(sim(z_f^i, z_m^j) / τ)
      └─ 여성 i와 모든 남성 j 사이의 (가중치 적용된) 유사도의 합
      └─ 이 값이 커지면 여성이 남성과 가까워짐

분모: 분자 + Σ exp(sim(z_f^i, z_f^k) / τ)  (k ≠ i)
           └─ 여성 i와 다른 여성 k 사이의 유사도의 합
           └─ 전체 대비 분자 비율 = 남성 방향으로 얼마나 당겨졌는가

전체: -log(분자/분모)
      └─ 분자/분모가 1에 가까워지면 loss → 0
      └─ 즉, 남성과 가깝고 다른 여성과 멀면 loss 감소
```

### 4.3.2 Male → Female 방향 Loss (역방향, 보조)

$$
\mathcal{L}_{M \rightarrow F} = -\frac{1}{N_m} \sum_{j=1}^{N_m} \log \frac{\sum_{i=1}^{N_f} \exp(s_{ji}^{m \rightarrow f})}{\sum_{i=1}^{N_f} \exp(s_{ji}^{m \rightarrow f}) + \sum_{k \neq j}^{N_m} \exp(s_{jk}^{m \rightarrow m})}
$$

### 4.3.3 비대칭 결합

$$
\mathcal{L}_{contrastive} = 1.5 \times \mathcal{L}_{F \rightarrow M} + 0.5 \times \mathcal{L}_{M \rightarrow F}
$$

**비대칭인 이유:**
- **F→M (1.5)**: 주 목적. 여성을 남성 방향으로 강하게 당김
- **M→F (0.5)**: 보조. 학습 안정성을 위해 역방향도 약하게 유지

## 4.4 Wasserstein Loss (보조 Loss)

Score 분포 수준에서 여성 → 남성 정렬을 돕는 보조 loss

$$
\mathcal{L}_{wass} = \frac{1}{K} \sum_{k=1}^{K} \max(0, s_m^{(k)} - s_f^{(k)})
$$

여기서 $s_m^{(k)}$와 $s_f^{(k)}$는 정렬된 score의 k번째 값

**직관:**
- 여성 score가 남성 score보다 낮을 때만 penalty
- 여성 score ≥ 남성 score이면 이 항은 0

## 4.5 Detection Loss

DETR의 원래 학습 loss (Hungarian matching 기반)

$$
\mathcal{L}_{det} = \lambda_{cls} \mathcal{L}_{cls} + \lambda_{L1} \mathcal{L}_{L1} + \lambda_{giou} \mathcal{L}_{giou}
$$

**역할:** Perturbation을 추가해도 탐지 성능 자체가 무너지지 않도록 유지

## 4.6 Total Loss

$$
\mathcal{L}_{total} = \lambda_c \mathcal{L}_{contrastive} + \lambda_w \mathcal{L}_{wass} + \beta \mathcal{L}_{det}
$$

| 하이퍼파라미터 | 기본값 | 역할 |
|---------------|--------|------|
| $\lambda_c$ | 1.0 | Contrastive loss 가중치 |
| $\lambda_w$ | 0.2 | Wasserstein loss 가중치 |
| $\beta$ | 0.5 → 0.6 | Detection loss 가중치 (스케줄링) |

---

# 5. 전체 파이프라인

## 5.1 시스템 구성도

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                         FAAP Training Pipeline                               │
└─────────────────────────────────────────────────────────────────────────────┘

                              ┌─────────────────┐
                              │   Input Batch   │
                              │  (Images +      │
                              │   Gender labels)│
                              └────────┬────────┘
                                       │
                                       ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  STEP 1: Gender-Balanced Sampling                                            │
│  ────────────────────────────────────────────────────────────────────────── │
│  • Female/Male 균등 샘플링                                                   │
│  • 조건: batch 내 female ≥ 2, male ≥ 1                                      │
│  • 목적: 매 배치에서 양쪽 성별 데이터 확보                                   │
└─────────────────────────────────────────────────────────────────────────────┘
                                       │
                                       ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  STEP 2: Perturbation Generation                                             │
│  ────────────────────────────────────────────────────────────────────────── │
│                                                                              │
│   Original Image (x)                    Perturbation Generator (G)          │
│   ┌─────────────────┐                   ┌─────────────────────────┐         │
│   │                 │                   │  Conv layers            │         │
│   │  [H × W × 3]    │  ───────────────▶ │  + Residual blocks     │         │
│   │                 │                   │  + tanh × ε             │         │
│   └─────────────────┘                   └───────────┬─────────────┘         │
│                                                     │                        │
│                                                     ▼                        │
│                                         ┌─────────────────────────┐         │
│                                         │  δ (perturbation)       │         │
│                                         │  ||δ||_∞ ≤ ε = 0.10     │         │
│                                         └───────────┬─────────────┘         │
│                                                     │                        │
│   Perturbed Image = clamp(x + δ)    ◀──────────────┘                        │
│                                                                              │
│   ※ ε = 0.10 → 픽셀값 범위 [0,255] 기준 약 ±25                              │
│      사람 눈에 거의 구분 불가능한 수준                                        │
└─────────────────────────────────────────────────────────────────────────────┘
                                       │
                                       ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  STEP 3: Data Augmentation (SimCLR Style)                                    │
│  ────────────────────────────────────────────────────────────────────────── │
│                                                                              │
│   Augmentation Options:                                                      │
│   ┌────────────┬────────────────────────────────────────────────────────┐   │
│   │ none       │ 증강 없음                                               │   │
│   │ weak       │ ColorJitter(0.2, 0.2, 0.2, 0.05)                       │   │
│   │ medium     │ ColorJitter(0.3, 0.3, 0.3, 0.1)         [기본값]       │   │
│   │ strong     │ ColorJitter(0.4, 0.4, 0.4, 0.1) + Grayscale(p=0.2)    │   │
│   └────────────┴────────────────────────────────────────────────────────┘   │
│                                                                              │
│   목적: Feature 학습의 일반화 성능 향상                                      │
│         (Contrastive Learning에서 중요한 역할)                               │
└─────────────────────────────────────────────────────────────────────────────┘
                                       │
                                       ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  STEP 4: Frozen DETR Forward Pass                                            │
│  ────────────────────────────────────────────────────────────────────────── │
│                                                                              │
│   ┌─────────────┐     ┌──────────────┐     ┌──────────────┐                 │
│   │ Perturbed   │     │   Backbone   │     │ Transformer  │                 │
│   │   Image     │────▶│  (ResNet50)  │────▶│  Encoder/    │                 │
│   │             │     │              │     │  Decoder     │                 │
│   └─────────────┘     └──────────────┘     └──────┬───────┘                 │
│                                                   │                          │
│                              ┌────────────────────┼────────────────────┐     │
│                              │                    │                    │     │
│                              ▼                    ▼                    ▼     │
│                     ┌──────────────┐     ┌──────────────┐     ┌───────────┐ │
│                     │ pred_logits  │     │  pred_boxes  │     │ features  │ │
│                     │ (분류 확률)  │     │ (bbox 좌표)  │     │ (hidden)  │ │
│                     │ [B,100,92]   │     │ [B,100,4]    │     │ [B,100,   │ │
│                     │              │     │              │     │  256]     │ │
│                     └──────────────┘     └──────────────┘     └───────────┘ │
│                                                                              │
│   ※ DETR는 Frozen (학습되지 않음) - Perturbation Generator만 학습           │
└─────────────────────────────────────────────────────────────────────────────┘
                                       │
          ┌────────────────────────────┼────────────────────────────┐
          │                            │                            │
          ▼                            ▼                            ▼
┌──────────────────┐        ┌──────────────────┐        ┌──────────────────┐
│  Detection Loss  │        │  Score 계산      │        │  Projection Head │
│  (Hungarian)     │        │  (Top-K 평균)    │        │  (SimCLR)        │
└────────┬─────────┘        └────────┬─────────┘        └────────┬─────────┘
         │                           │                           │
         │                           ▼                           ▼
         │                  ┌──────────────────┐        ┌──────────────────┐
         │                  │ Image-level      │        │ L2-normalized    │
         │                  │ Detection Score  │        │ Projections      │
         │                  │ (B,)             │        │ (B, 128)         │
         │                  └────────┬─────────┘        └────────┬─────────┘
         │                           │                           │
         │                           └─────────────┬─────────────┘
         │                                         │
         │                                         ▼
         │                           ┌─────────────────────────────┐
         │                           │     Gender Split            │
         │                           │  ┌───────────────────────┐  │
         │                           │  │ Female: proj_f,       │  │
         │                           │  │         scores_f      │  │
         │                           │  │ Male:   proj_m,       │  │
         │                           │  │         scores_m      │  │
         │                           │  └───────────────────────┘  │
         │                           └─────────────┬───────────────┘
         │                                         │
         │                                         ▼
         │                           ┌─────────────────────────────┐
         │                           │  Gender-Aware Contrastive   │
         │                           │  Loss Computation           │
         │                           │  (Adaptive Weighting 적용)  │
         │                           └─────────────┬───────────────┘
         │                                         │
         │              ┌──────────────────────────┼──────────────────────────┐
         │              │                          │                          │
         │              ▼                          ▼                          │
         │    ┌──────────────────┐      ┌──────────────────┐                  │
         │    │ L_contrastive    │      │ L_wasserstein    │                  │
         │    │ (핵심 Loss)      │      │ (보조 Loss)      │                  │
         │    └────────┬─────────┘      └────────┬─────────┘                  │
         │             │                         │                            │
         └─────────────┼─────────────────────────┼────────────────────────────┘
                       │                         │
                       ▼                         ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  STEP 5: Total Loss Computation                                              │
│  ────────────────────────────────────────────────────────────────────────── │
│                                                                              │
│   L_total = λ_c × L_contrastive + λ_w × L_wasserstein + β × L_det           │
│                                                                              │
│   기본값:  λ_c = 1.0,  λ_w = 0.2,  β = 0.5 → 0.6 (스케줄링)                 │
│                                                                              │
│   β 스케줄링:                                                                │
│   ┌────────────────────────────────────────────────────────────────────┐    │
│   │  β(epoch) = β_start + (β_final - β_start) × (epoch / total_epochs) │    │
│   │                                                                     │    │
│   │  초기 (β=0.5): 공정성 학습에 집중                                   │    │
│   │  후기 (β=0.6): Detection 성능 유지에 더 신경                        │    │
│   └────────────────────────────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────────────────────────┘
                                       │
                                       ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  STEP 6: Backpropagation & Optimization                                      │
│  ────────────────────────────────────────────────────────────────────────── │
│                                                                              │
│   학습되는 파라미터:                                                         │
│   • Perturbation Generator                                                   │
│   • Projection Head                                                          │
│                                                                              │
│   학습되지 않는 파라미터 (Frozen):                                           │
│   • DETR 전체                                                                │
│                                                                              │
│   Optimizer: AdamW (lr=1e-4, weight_decay=0.01)                             │
│   Gradient Clipping: max_norm=0.1                                            │
└─────────────────────────────────────────────────────────────────────────────┘
```

## 5.2 Image-Level Score 계산 상세

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                   Image-Level Detection Score 계산                           │
└─────────────────────────────────────────────────────────────────────────────┘

DETR Output: pred_logits [B, 100, 92]
             └─ B: 배치 크기
             └─ 100: object queries 수
             └─ 92: 클래스 수 (91 COCO classes + 1 no-object)

Step 1: Softmax → 확률로 변환
        probs = softmax(pred_logits, dim=-1)
        probs = probs[..., :-1]  # no-object 클래스 제외
        결과: [B, 100, 91]

Step 2: Query별 최대 확률
        max_probs = probs.max(dim=-1).values
        결과: [B, 100]
        └─ 각 query가 "무언가를 탐지했다"고 확신하는 정도

Step 3: Top-K 평균 (K=10)
        topk_probs = max_probs.topk(k=10, dim=1).values
        image_score = topk_probs.mean(dim=1)
        결과: [B]
        └─ 이미지 전체의 "탐지 품질" 점수

┌────────────────────────────────────────────────────────────────────────────┐
│  예시:                                                                      │
│                                                                             │
│  Query 1: person 0.85, car 0.12, ...   → max = 0.85                        │
│  Query 2: person 0.72, dog 0.21, ...   → max = 0.72                        │
│  Query 3: car 0.03, person 0.02, ...   → max = 0.03  (거의 탐지 안 됨)     │
│  ...                                                                        │
│  Query 100: ...                         → max = 0.01                        │
│                                                                             │
│  Top-10: [0.85, 0.72, 0.68, 0.65, 0.61, 0.58, 0.52, 0.48, 0.45, 0.42]      │
│  Image Score = 0.596                                                        │
│                                                                             │
│  해석: 이 이미지에서 상위 10개 탐지의 평균 신뢰도는 59.6%                   │
└────────────────────────────────────────────────────────────────────────────┘
```

---

# 6. 모델 아키텍처 상세

## 6.1 Perturbation Generator

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                    Perturbation Generator Architecture                       │
└─────────────────────────────────────────────────────────────────────────────┘

Input: Normalized Image [B, 3, H, W]
       값 범위: 약 [-2.1, 2.6] (ImageNet normalization 후)

┌──────────────────────────────────────────────────────────────────────────┐
│                                                                           │
│   ┌─────────────┐                                                         │
│   │   Input     │  [B, 3, H, W]                                           │
│   └──────┬──────┘                                                         │
│          │                                                                │
│          ▼                                                                │
│   ┌─────────────┐                                                         │
│   │  Conv2d     │  3 → 64 channels, kernel=3, padding=1                  │
│   │  + ReLU     │                                                         │
│   └──────┬──────┘                                                         │
│          │                                                                │
│          ▼                                                                │
│   ┌─────────────┐                                                         │
│   │  Residual   │  여러 개의 Residual Block                               │
│   │  Blocks     │  (feature 추출 및 변환)                                 │
│   └──────┬──────┘                                                         │
│          │                                                                │
│          ▼                                                                │
│   ┌─────────────┐                                                         │
│   │  Conv2d     │  64 → 3 channels, kernel=3, padding=1                  │
│   └──────┬──────┘                                                         │
│          │                                                                │
│          ▼                                                                │
│   ┌─────────────┐                                                         │
│   │   tanh      │  출력을 [-1, 1] 범위로 제한                            │
│   └──────┬──────┘                                                         │
│          │                                                                │
│          ▼                                                                │
│   ┌─────────────┐                                                         │
│   │  × epsilon  │  [-ε, ε] 범위로 스케일링 (ε = 0.10)                    │
│   └──────┬──────┘                                                         │
│          │                                                                │
│          ▼                                                                │
│   ┌─────────────┐                                                         │
│   │   Output    │  Perturbation δ [B, 3, H, W]                           │
│   │             │  ||δ||_∞ ≤ 0.10 보장                                   │
│   └─────────────┘                                                         │
│                                                                           │
└──────────────────────────────────────────────────────────────────────────┘

Perturbation 적용:
    perturbed = clamp(original + δ)

    clamp 함수: ImageNet normalization 범위 내로 제한
                각 채널별 [mean - k*std, mean + k*std]
```

## 6.2 SimCLR Projection Head

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                    SimCLR Projection Head Architecture                       │
└─────────────────────────────────────────────────────────────────────────────┘

Input: DETR Transformer Features [B, 100, 256]
       └─ B: 배치 크기
       └─ 100: object queries
       └─ 256: hidden dimension

┌──────────────────────────────────────────────────────────────────────────┐
│                                                                           │
│   ┌─────────────────────────────────────────────────────────────────┐    │
│   │  Input Features                                                  │    │
│   │  [B, 100, 256]                                                   │    │
│   └──────────────────────────────┬──────────────────────────────────┘    │
│                                  │                                        │
│                                  ▼                                        │
│   ┌─────────────────────────────────────────────────────────────────┐    │
│   │  Mean Pooling (dim=1)                                            │    │
│   │                                                                  │    │
│   │  100개 query의 feature를 평균                                    │    │
│   │  → 이미지 전체를 대표하는 단일 벡터                              │    │
│   │                                                                  │    │
│   │  [B, 100, 256] → [B, 256]                                        │    │
│   └──────────────────────────────┬──────────────────────────────────┘    │
│                                  │                                        │
│                                  ▼                                        │
│   ┌─────────────────────────────────────────────────────────────────┐    │
│   │  Linear Layer 1                                                  │    │
│   │  256 → 256                                                       │    │
│   └──────────────────────────────┬──────────────────────────────────┘    │
│                                  │                                        │
│                                  ▼                                        │
│   ┌─────────────────────────────────────────────────────────────────┐    │
│   │  ReLU Activation                                                 │    │
│   └──────────────────────────────┬──────────────────────────────────┘    │
│                                  │                                        │
│                                  ▼                                        │
│   ┌─────────────────────────────────────────────────────────────────┐    │
│   │  Linear Layer 2                                                  │    │
│   │  256 → 128                                                       │    │
│   └──────────────────────────────┬──────────────────────────────────┘    │
│                                  │                                        │
│                                  ▼                                        │
│   ┌─────────────────────────────────────────────────────────────────┐    │
│   │  L2 Normalization                                                │    │
│   │                                                                  │    │
│   │  z = z / ||z||_2                                                 │    │
│   │                                                                  │    │
│   │  → 단위 초구면(unit hypersphere) 위의 점으로 변환               │    │
│   │  → Cosine similarity = Dot product                               │    │
│   └──────────────────────────────┬──────────────────────────────────┘    │
│                                  │                                        │
│                                  ▼                                        │
│   ┌─────────────────────────────────────────────────────────────────┐    │
│   │  Output Projection                                               │    │
│   │  [B, 128]                                                        │    │
│   │                                                                  │    │
│   │  ||z||_2 = 1 (L2 norm = 1)                                       │    │
│   └─────────────────────────────────────────────────────────────────┘    │
│                                                                           │
└──────────────────────────────────────────────────────────────────────────┘

왜 Projection Head가 필요한가?

1. 차원 축소: 256 → 128
   - 계산 효율성 향상
   - 과적합 방지

2. 비선형 변환:
   - 원본 feature 공간과 분리된 공간에서 contrastive 학습
   - Detection에 필요한 정보 보존하면서 공정성 학습

3. L2 정규화:
   - 모든 feature가 동일한 크기 → 방향만으로 비교
   - Cosine similarity 계산 단순화
```

---

# 7. 하이퍼파라미터 설정

## 7.1 전체 하이퍼파라미터 표

| 카테고리 | 파라미터 | 기본값 | 설명 | 영향 |
|----------|----------|--------|------|------|
| **학습** | epochs | 24 | 총 학습 에폭 | 너무 적으면 수렴 안 됨, 너무 많으면 과적합 |
| | batch_size | 8 | 배치 크기 | 클수록 안정적, GPU 메모리 한계 |
| | lr_g | 1e-4 | Generator 학습률 | 핵심 파라미터 |
| | seed | 42 | 랜덤 시드 | 재현성 |
| **Perturbation** | epsilon | 0.10 | 최대 섭동 크기 | 너무 작으면 효과 없음, 너무 크면 이미지 왜곡 |
| **Contrastive** | temperature | 0.07 | InfoNCE 온도 | 작을수록 hard negative에 집중 |
| | score_weight_alpha | 1.0 | Score 가중치 강도 | 클수록 score 차이에 민감 |
| | proj_dim | 128 | Projection 차원 | 표현력과 효율성 균형 |
| | score_top_k | 10 | Score 계산 Top-K | 탐지 품질 측정 세밀도 |
| **Loss 가중치** | lambda_contrastive | 1.0 | Contrastive loss 가중치 | 공정성 학습 강도 |
| | lambda_wass | 0.2 | Wasserstein loss 가중치 | Score 분포 정렬 강도 |
| | beta | 0.5 | Detection loss 초기 가중치 | 탐지 성능 유지 |
| | beta_final | 0.6 | Detection loss 최종 가중치 | 후반 탐지 성능 강화 |
| **Augmentation** | aug_strength | medium | 증강 강도 | 일반화 vs 안정성 |
| **기타** | max_norm | 0.1 | Gradient clipping | 학습 안정성 |
| | num_workers | 6 | 데이터 로딩 워커 수 | 학습 속도 |

## 7.2 핵심 하이퍼파라미터 분석

### Temperature (τ = 0.07)

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                    Temperature의 영향                                        │
└─────────────────────────────────────────────────────────────────────────────┘

τ가 작을 때 (0.07):
  • exp(sim/τ)의 값 차이가 극대화됨
  • 가장 유사한 positive에 집중
  • "hard" contrastive learning

τ가 클 때 (1.0):
  • exp(sim/τ)의 값 차이가 작아짐
  • 모든 샘플을 균등하게 고려
  • "soft" contrastive learning

예시 (similarity = 0.8 vs 0.5):
┌────────────┬───────────────────────┬───────────────────────┐
│     τ      │  exp(0.8/τ)           │  exp(0.5/τ)           │
├────────────┼───────────────────────┼───────────────────────┤
│    0.07    │  9.2 × 10^4           │  1.3 × 10^3           │
│    0.5     │  4.95                 │  2.72                 │
│    1.0     │  2.23                 │  1.65                 │
└────────────┴───────────────────────┴───────────────────────┘

→ τ=0.07일 때 두 값의 비율: 70배 차이
→ τ=1.0일 때 두 값의 비율: 1.35배 차이

결론: 작은 τ는 가장 유사한 positive/negative를 강조
```

### Epsilon (ε = 0.10)

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                    Epsilon의 의미                                            │
└─────────────────────────────────────────────────────────────────────────────┘

ε = 0.10 (normalized space에서)

ImageNet normalization:
  mean = [0.485, 0.456, 0.406]
  std  = [0.229, 0.224, 0.225]

원본 픽셀 공간 [0, 1]에서의 perturbation:
  δ_pixel ≈ ε × std ≈ 0.10 × 0.225 ≈ 0.0225

픽셀값 [0, 255]에서:
  δ_255 ≈ 0.0225 × 255 ≈ 5.7

결론: 각 픽셀당 최대 약 ±6 (255 스케일 기준) 변화
      → 사람 눈에 거의 구분 불가능
      → 모델에는 충분한 영향
```

---

# 8. 학습 과정 모니터링

## 8.1 로그 메트릭 해석

| 메트릭 | 정상 범위 | 해석 |
|--------|----------|------|
| `loss_contrastive` | 0.5 ~ 2.0 | 낮을수록 성별 간 feature 정렬 잘 됨 |
| `loss_wasserstein` | 0.0 ~ 0.1 | 낮을수록 score 분포 정렬 잘 됨 |
| `loss_det` | 1.0 ~ 3.0 | DETR 원래 수준 유지가 목표 |
| `score_f` | 0.3 ~ 0.5 | 여성 평균 탐지 점수 |
| `score_m` | 0.3 ~ 0.5 | 남성 평균 탐지 점수 |
| `score_gap` | 목표: → 0 | score_m - score_f, 줄어들어야 함 |
| `delta_linf` | ≤ 0.10 | Perturbation 크기 (epsilon 이하여야 함) |

## 8.2 학습 진행 예상 패턴

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                    예상 학습 곡선                                            │
└─────────────────────────────────────────────────────────────────────────────┘

Loss
  │
3 │ ╲
  │  ╲_____
2 │        ╲____
  │             ╲___
1 │                 ╲____________________
  │
0 └─────────────────────────────────────────▶ Epoch
    0    4    8    12   16   20   24

Score Gap (M-F)
  │
0.10│ ────────╲
    │          ╲
0.05│           ╲____
    │                ╲_______________
0.00│ ─────────────────────────────────▶ Epoch
    0    4    8    12   16   20   24

※ Score gap이 줄어들지 않거나 loss가 발산하면 하이퍼파라미터 조정 필요
```

---

# 9. 실험 설정 및 평가

## 9.1 데이터셋

| 항목 | 값 |
|------|-----|
| 데이터셋 | FAAP Dataset (COCO 기반) |
| Task | Person Detection |
| 성별 라벨 | 이미지 단위 (Female/Male) |
| Train/Val 분할 | 표준 COCO split |

## 9.2 평가 메트릭

| 메트릭 | 정의 | 목표 |
|--------|------|------|
| AP (Average Precision) | COCO 표준 AP@[.5:.95] | 전체 성능 |
| AP_Female | 여성 이미지에서의 AP | 향상 필요 |
| AP_Male | 남성 이미지에서의 AP | 유지 |
| **AP Gap** | AP_Male - AP_Female | **최소화** |

## 9.3 성공 기준

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                    성공 기준 (Success Criteria)                              │
└─────────────────────────────────────────────────────────────────────────────┘

Baseline (DETR without FAAP):
  • AP_Male:   0.511
  • AP_Female: 0.404
  • AP Gap:    0.107

목표 (FAAP 적용 후):
  ┌────────────────────────────────────────────────────────────┐
  │  AP Gap < 0.09                                             │
  │  (Baseline 0.107 대비 16% 이상 개선)                       │
  │                                                            │
  │  AP_Female > 0.41                                          │
  │  (Baseline 0.404 대비 향상)                                │
  │                                                            │
  │  AP_Male ≈ 0.50+                                           │
  │  (큰 하락 없이 유지)                                       │
  └────────────────────────────────────────────────────────────┘

이상적인 결과:
  • AP_Male:   0.50 (약간 하락 허용)
  • AP_Female: 0.42+
  • AP Gap:    0.08 이하
```

---

# 10. 2nd vs 3rd 버전 비교 요약

| 항목 | 2nd 버전 | 3rd 버전 |
|------|---------|---------|
| **분리 기준** | Score만 | Gender + Score |
| **Anchor** | Low-score 샘플 (성별 무관) | Female 샘플 |
| **Positive** | High-score 샘플 (성별 무관) | Male 샘플 |
| **Negative** | 다른 Low-score 샘플 | 다른 Female 샘플 |
| **가중치** | 없음 (균등) | Score 차이 기반 adaptive |
| **방향성** | 대칭 | 비대칭 (F→M 1.5, M→F 0.5) |
| **문제점** | Score 분리가 성별과 무관 | - |
| **예상 결과** | AP Gap 악화 | AP Gap 개선 기대 |

---

# 11. 코드 실행 방법

## 11.1 기본 실행

```bash
python train_faap_simclr_infonce_3rd.py \
    --dataset_root /path/to/faap_dataset \
    --epochs 24 \
    --batch_size 8 \
    --lr_g 1e-4
```

## 11.2 분산 학습 (Multi-GPU)

```bash
torchrun --nproc_per_node=4 train_faap_simclr_infonce_3rd.py \
    --distributed \
    --dataset_root /path/to/faap_dataset
```

## 11.3 체크포인트에서 재개

```bash
python train_faap_simclr_infonce_3rd.py \
    --resume faap_outputs/faap_outputs_infonce_3rd/checkpoints/epoch_0012.pth
```

---

# 12. 출력 구조

```
faap_outputs/faap_outputs_infonce_3rd/
│
├── config.json              # 학습 설정 저장
│   {
│     "epochs": 24,
│     "batch_size": 8,
│     "lr_g": 0.0001,
│     "epsilon": 0.10,
│     "temperature": 0.07,
│     ...
│   }
│
├── dataset_layout.json      # 데이터셋 통계
│
├── train_log.jsonl          # 에폭별 학습 로그 (JSON Lines)
│   {"epoch": 0, "loss_contrastive": 1.23, "score_gap": 0.08, ...}
│   {"epoch": 1, "loss_contrastive": 1.15, "score_gap": 0.07, ...}
│   ...
│
└── checkpoints/
    ├── epoch_0000.pth       # 에폭별 체크포인트
    ├── epoch_0001.pth
    ├── ...
    └── epoch_0023.pth
```

---

# 13. 요약

## 13.1 문제

DETR 모델에서 **여성 탐지 성능이 남성 대비 10.7%p 낮음** (AP Gap = 0.107)

## 13.2 해결책

**Gender-Aware Score-Based Contrastive Learning**
- 여성 이미지의 feature를 남성 이미지 feature 방향으로 당김
- Score 차이에 비례한 adaptive weighting 적용
- 기존 DETR 모델 수정 없이 perturbation만 추가

## 13.3 핵심 기여

1. **명시적 성별 정보 활용**: 2nd 버전의 실패 원인 분석 및 해결
2. **Adaptive Weighting**: Score 차이 기반 학습 신호 강도 조절
3. **비대칭 학습**: F→M 방향 강조로 목적에 부합하는 학습

## 13.4 기대 효과

| 메트릭 | Baseline | 목표 |
|--------|----------|------|
| AP Gap | 10.7%p | < 9%p |
| Female AP | 40.4% | > 41% |
| Male AP | 51.1% | ≈ 50% (유지) |

---

# 14. 실험 결과

## 14.1 실험 환경

| 항목 | 값 |
|------|-----|
| 모델 | DETR-R50 (Frozen) |
| 데이터셋 | FAAP Dataset (COCO 기반) |
| 평가 Split | Test Set |
| Epochs | 24 |
| Perturbation ε | 0.10 |

## 14.2 정량적 결과

### 14.2.1 전체 비교표

```
┌─────────────────────────────────────────────────────────────────────────────────────────────────┐
│                              실험 결과 비교 (Test Set)                                           │
├─────────────────────────────────────────────────────────────────────────────────────────────────┤
│                                                                                                  │
│  ┌─────────────────┬──────────┬──────────┬──────────┬──────────┬──────────┬──────────┐         │
│  │                 │ Male AP  │ Female AP│  AP Gap  │ Male AR  │Female AR │  AR Gap  │         │
│  ├─────────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤         │
│  │ Baseline        │  0.511   │  0.404   │  10.6%p  │  0.834   │  0.826   │  0.8%p   │         │
│  ├─────────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤         │
│  │ WGAN 7th        │  0.514   │  0.408   │  10.6%p  │  0.836   │  0.833   │  0.3%p   │         │
│  │ (Epoch 23)      │(+0.3%p)  │(+0.4%p)  │ (0%p)    │(+0.2%p)  │(+0.7%p)  │(-0.5%p)  │         │
│  ├─────────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤         │
│  │ InfoNCE 3rd     │  0.517   │  0.413   │  10.5%p  │  0.837   │  0.833   │  0.4%p   │         │
│  │ (Epoch 10)      │(+0.7%p)  │(+0.8%p)  │(-0.1%p)  │(+0.3%p)  │(+0.8%p)  │(-0.4%p)  │         │
│  ├─────────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤         │
│  │ InfoNCE 3rd     │  0.518   │  0.408   │  10.9%p  │  0.838   │  0.831   │  0.8%p   │         │
│  │ (Epoch 23)      │(+0.7%p)  │(+0.4%p)  │(+0.3%p)  │(+0.4%p)  │(+0.5%p)  │ (0%p)    │         │
│  └─────────────────┴──────────┴──────────┴──────────┴──────────┴──────────┴──────────┘         │
│                                                                                                  │
│  ※ 괄호 안: Baseline 대비 변화량 (%p = percentage point, 퍼센트 포인트)                         │
│  ※ AP Gap, AR Gap은 낮을수록 좋음 (공정성 향상)                                                 │
└─────────────────────────────────────────────────────────────────────────────────────────────────┘
```

### 14.2.2 상세 수치 (InfoNCE 3rd)

**실험 1: Epoch 10 (Best)**

| 메트릭 | Baseline | Perturbed | Delta (%p) |
|--------|----------|-----------|------------|
| Male AP | 51.08% | 51.74% | **+0.66%p** |
| Female AP | 40.45% | 41.26% | **+0.81%p** |
| **AP Gap** | **10.63%p** | **10.48%p** | **-0.15%p** |
| Male AR | 83.39% | 83.70% | **+0.31%p** |
| Female AR | 82.58% | 83.34% | **+0.76%p** |
| **AR Gap** | **0.81%p** | **0.36%p** | **-0.45%p** |

**실험 2: Epoch 23 (Final)**

| 메트릭 | Baseline | Perturbed | Delta (%p) |
|--------|----------|-----------|------------|
| Male AP | 51.08% | 51.76% | **+0.68%p** |
| Female AP | 40.45% | 40.82% | **+0.37%p** |
| **AP Gap** | **10.63%p** | **10.95%p** | **+0.32%p** |
| Male AR | 83.39% | 83.83% | **+0.44%p** |
| Female AR | 82.58% | 83.06% | **+0.49%p** |
| **AR Gap** | **0.81%p** | **0.77%p** | **-0.04%p** |

### 14.2.3 WGAN 7th vs InfoNCE 3rd 비교

```
┌─────────────────────────────────────────────────────────────────────────────────────────────────┐
│                         방법론 비교 분석                                                         │
├─────────────────────────────────────────────────────────────────────────────────────────────────┤
│                                                                                                  │
│   [AP Gap 변화]                            [AR Gap 변화]                                         │
│                                                                                                  │
│   Baseline: ████████████████████ 10.6%p    Baseline: ████████████████████ 0.8%p               │
│                                                                                                  │
│   WGAN 7th: ███████████████████▌ 10.6%p    WGAN 7th: ███████▌            0.3%p  ✓ Best        │
│             (0%p)                                     (-0.5%p)                                   │
│                                                                                                  │
│   3rd E10:  ███████████████████  10.5%p    3rd E10:  █████████           0.4%p  ✓ Good         │
│             (-0.1%p)                                  (-0.4%p)                                   │
│                                                                                                  │
│   3rd E23:  █████████████████████ 10.9%p   3rd E23:  ███████████████████ 0.8%p                 │
│             (+0.3%p) ✗                                (0%p)                                      │
│                                                                                                  │
│   ──────────────────────────────────────────────────────────────────────────────────────────    │
│                                                                                                  │
│   [Female AP 변화]                                                                               │
│                                                                                                  │
│   Baseline: ████████████████████ 40.4%                                                          │
│                                                                                                  │
│   WGAN 7th: ████████████████████▌ 40.8%  (+0.4%p)                                              │
│                                                                                                  │
│   3rd E10:  █████████████████████ 41.3%  (+0.8%p) ✓ Best                                       │
│                                                                                                  │
│   3rd E23:  ████████████████████▌ 40.8%  (+0.4%p)                                              │
│                                                                                                  │
└─────────────────────────────────────────────────────────────────────────────────────────────────┘
```

## 14.3 결과 분석

### 14.3.1 InfoNCE 3rd 분석

**긍정적 결과 (Epoch 10)**
- Female AP: 40.4% → 41.3% **(+0.8%p)** - **목표 달성 (> 41%)**
- AP Gap: 10.6%p → 10.5%p **(-0.1%p)** - 미미한 개선
- AR Gap: 0.8%p → 0.4%p **(-0.4%p)** - **유의미한 개선**

**부정적 결과 (Epoch 23)**
- AP Gap이 baseline보다 악화 (10.6%p → 10.9%p, **+0.3%p**)
- Male AP 향상 폭 > Female AP 향상 폭 → 불균형 학습

### 14.3.2 과적합 문제 분석

```
┌─────────────────────────────────────────────────────────────────────────────────────────────────┐
│                           과적합(Overfitting) 분석                                               │
├─────────────────────────────────────────────────────────────────────────────────────────────────┤
│                                                                                                  │
│   Female AP 변화 추이                                                                            │
│                                                                                                  │
│   0.413 │           ●  (Epoch 10: Best)                                                         │
│         │          /  \                                                                          │
│   0.410 │         /    \                                                                         │
│         │        /      \                                                                        │
│   0.408 │ ──────●────────●─────────● (Epoch 23)                                                 │
│         │     /                                                                                  │
│   0.404 │ ● (Baseline)                                                                          │
│         └───────────────────────────────────▶ Epoch                                             │
│           0    5    10   15   20   23                                                           │
│                                                                                                  │
│   관찰:                                                                                          │
│   • Epoch 10까지: Female AP 상승 (학습 효과)                                                     │
│   • Epoch 10 이후: Female AP 하락 (과적합)                                                       │
│   • Male AP는 계속 상승 → 불균형 학습                                                            │
│                                                                                                  │
│   원인 분석:                                                                                     │
│   1. Projection Head가 Training Set에 과적합                                                    │
│   2. Score Gap 역전: 학습 중 score_m < score_f 현상 발생                                        │
│   3. Adaptive Weighting이 의도와 반대로 작용                                                    │
└─────────────────────────────────────────────────────────────────────────────────────────────────┘
```

### 14.3.3 WGAN 7th과의 비교 분석

| 비교 항목 | WGAN 7th | InfoNCE 3rd (E10) | 우위 |
|-----------|----------|-------------------|------|
| AP Gap 개선 | 0%p | -0.1%p | InfoNCE |
| AR Gap 개선 | -0.5%p | -0.4%p | WGAN |
| Female AP 향상 | +0.4%p | +0.8%p | InfoNCE |
| 학습 안정성 | 안정적 | 과적합 발생 | WGAN |
| 최적 Epoch | 23 (최종) | 10 (중간) | WGAN |

---

# 15. 결론 및 최종 평가

## 15.1 성공 기준 대비 평가

```
┌─────────────────────────────────────────────────────────────────────────────────────────────────┐
│                              성공 기준 달성 여부                                                 │
├─────────────────────────────────────────────────────────────────────────────────────────────────┤
│                                                                                                  │
│   목표 1: AP Gap < 9%p                                                                          │
│   ┌───────────────────────────────────────────────────────────────────────────┐                 │
│   │  Baseline:       10.6%p                                                   │                 │
│   │  InfoNCE 3rd:    10.5%p (Epoch 10) / 10.9%p (Epoch 23)                   │                 │
│   │  달성 여부:      ✗ 미달성 (목표 9%p 대비 미흡)                           │                 │
│   └───────────────────────────────────────────────────────────────────────────┘                 │
│                                                                                                  │
│   목표 2: Female AP > 41%                                                                       │
│   ┌───────────────────────────────────────────────────────────────────────────┐                 │
│   │  Baseline:       40.4%                                                    │                 │
│   │  InfoNCE 3rd:    41.3% (Epoch 10) / 40.8% (Epoch 23)                     │                 │
│   │  달성 여부:      ✓ 달성 (Epoch 10 기준)                                  │                 │
│   └───────────────────────────────────────────────────────────────────────────┘                 │
│                                                                                                  │
│   목표 3: Male AP ≈ 50% 유지                                                                    │
│   ┌───────────────────────────────────────────────────────────────────────────┐                 │
│   │  Baseline:       51.1%                                                    │                 │
│   │  InfoNCE 3rd:    51.7% (Epoch 10) / 51.8% (Epoch 23)                     │                 │
│   │  달성 여부:      ✓ 달성 (오히려 +0.7%p 향상)                             │                 │
│   └───────────────────────────────────────────────────────────────────────────┘                 │
│                                                                                                  │
│   ═══════════════════════════════════════════════════════════════════════════                   │
│   최종 결과: 부분적 성공 (2/3 목표 달성)                                                        │
│   ═══════════════════════════════════════════════════════════════════════════                   │
│                                                                                                  │
└─────────────────────────────────────────────────────────────────────────────────────────────────┘
```

## 15.2 최종 결론

### 15.2.1 InfoNCE 3rd 버전 평가

| 평가 항목 | 결과 | 상세 |
|-----------|------|------|
| **AP Gap 개선** | △ 부분 성공 | Epoch 10에서 -0.15%p 개선, 그러나 목표(9%p) 미달 |
| **AR Gap 개선** | ✓ 성공 | -0.45%p 개선 (0.81%p → 0.36%p) |
| **Female AP 향상** | ✓ 성공 | +0.81%p 향상 (40.4% → 41.3%), 목표(41%) 달성 |
| **Male AP 유지** | ✓ 성공 | 오히려 +0.66%p 향상 |
| **학습 안정성** | ✗ 실패 | 과적합 발생, Early Stopping 필요 |

### 15.2.2 WGAN 7th 대비 평가

```
┌─────────────────────────────────────────────────────────────────────────────────────────────────┐
│                          WGAN 7th vs InfoNCE 3rd 최종 비교                                       │
├─────────────────────────────────────────────────────────────────────────────────────────────────┤
│                                                                                                  │
│   ┌───────────────────────────────┬───────────────────────────────┐                             │
│   │         WGAN 7th              │       InfoNCE 3rd (E10)       │                             │
│   ├───────────────────────────────┼───────────────────────────────┤                             │
│   │  AP Gap:  10.6%p (0%p)        │  AP Gap:  10.5%p (-0.1%p)     │ ← InfoNCE 우위              │
│   │  AR Gap:  0.3%p (-0.5%p)      │  AR Gap:  0.4%p (-0.4%p)      │ ← WGAN 우위                 │
│   │  Female AP: 40.8% (+0.4%p)    │  Female AP: 41.3% (+0.8%p)    │ ← InfoNCE 우위              │
│   │  안정성: ✓ 높음               │  안정성: △ 과적합 문제        │ ← WGAN 우위                 │
│   └───────────────────────────────┴───────────────────────────────┘                             │
│                                                                                                  │
│   종합 평가:                                                                                     │
│   • AP 기준 공정성: InfoNCE 3rd (E10) 우위                                                      │
│   • AR 기준 공정성: WGAN 7th 우위                                                               │
│   • 실용성 (안정성): WGAN 7th 우위                                                              │
│                                                                                                  │
│   권장 사용:                                                                                     │
│   • AR Gap 중시 → WGAN 7th                                                                      │
│   • AP Gap + Female AP 중시 → InfoNCE 3rd (Early Stopping 필수)                                │
│                                                                                                  │
└─────────────────────────────────────────────────────────────────────────────────────────────────┘
```

## 15.3 연구 의의

### 15.3.1 학술적 기여

1. **Gender-Aware Contrastive Learning 프레임워크 제안**
   - 성별 정보를 명시적으로 활용한 새로운 공정성 학습 방법
   - 기존 Score-only 방식(2nd)의 한계 극복

2. **Adaptive Score Weighting 메커니즘**
   - Detection score 차이에 비례한 학습 강도 조절
   - 저성능 그룹에 집중적인 학습 신호 전달

3. **비대칭 Contrastive Learning**
   - F→M (1.5) vs M→F (0.5) 비대칭 가중치
   - 목적에 부합하는 단방향 학습 강조

### 15.3.2 실용적 시사점

1. **Early Stopping의 중요성**
   - Epoch 10에서 최적 성능 → 과적합 방지 전략 필수
   - Validation 기반 모델 선택 권장

2. **Contrastive vs Adversarial 트레이드오프**
   - Contrastive: AP 공정성에 효과적, 불안정
   - Adversarial: AR 공정성에 효과적, 안정적

3. **하이브리드 접근 가능성**
   - Contrastive + Adversarial 결합으로 양쪽 장점 활용 가능

## 15.4 한계점 및 향후 연구 방향

### 15.4.1 현재 한계점

| 한계 | 상세 | 영향 |
|------|------|------|
| 과적합 | Epoch 10 이후 성능 하락 | Early Stopping 필요 |
| Score Gap 역전 | 학습 중 M < F 현상 | Adaptive Weighting 역효과 |
| AP Gap 목표 미달 | 10.5%p > 9%p (목표) | 추가 개선 필요 |

### 15.4.2 향후 연구 방향

1. **Score Normalization**
   - 배치 내 score 정규화로 역전 현상 방지
   - `score_norm = (score - mean) / std`

2. **Hard Negative Mining**
   - 가장 어려운 negative 샘플에 집중
   - 학습 효율성 향상

3. **Hybrid Loss 설계**
   - Contrastive + Adversarial 결합
   - `L = α*L_contrastive + β*L_adversarial + γ*L_det`

4. **Projection Head 정규화**
   - Dropout, Weight Decay 강화
   - 과적합 방지

---

# 16. 최종 요약

```
┌─────────────────────────────────────────────────────────────────────────────────────────────────┐
│                              FAAP InfoNCE 3rd 최종 요약                                          │
├─────────────────────────────────────────────────────────────────────────────────────────────────┤
│                                                                                                  │
│   [문제]                                                                                         │
│   DETR 모델의 성별 탐지 편향: Female AP 40.4% vs Male AP 51.1% (Gap: 10.6%p)                   │
│                                                                                                  │
│   [제안 방법]                                                                                    │
│   Gender-Aware Score-Based Contrastive Learning                                                 │
│   • 여성(Anchor) → 남성(Positive) 방향 feature 정렬                                             │
│   • Score 차이 기반 Adaptive Weighting                                                          │
│   • 비대칭 학습 (F→M: 1.5, M→F: 0.5)                                                           │
│                                                                                                  │
│   [주요 결과 - Epoch 10]                                                                        │
│   • Female AP: 40.4% → 41.3% (+0.8%p) ✓                                                        │
│   • AP Gap: 10.6%p → 10.5%p (-0.1%p) △                                                         │
│   • AR Gap: 0.8%p → 0.4%p (-0.4%p) ✓                                                           │
│                                                                                                  │
│   [성공 여부]                                                                                    │
│   부분적 성공 (2/3 목표 달성)                                                                   │
│   • ✓ Female AP > 41% 달성                                                                     │
│   • ✓ Male AP 유지 (오히려 +0.7%p 향상)                                                        │
│   • ✗ AP Gap < 9%p 미달성                                                                      │
│                                                                                                  │
│   [vs WGAN 7th]                                                                                 │
│   • AP 공정성: InfoNCE 우위 (-0.1%p vs 0%p)                                                    │
│   • AR 공정성: WGAN 우위 (-0.5%p vs -0.4%p)                                                    │
│   • 안정성: WGAN 우위                                                                           │
│                                                                                                  │
│   [핵심 교훈]                                                                                    │
│   1. Gender 정보 명시적 활용이 효과적                                                           │
│   2. Early Stopping 필수 (Epoch 10 권장)                                                        │
│   3. Contrastive Learning은 AP 공정성에 유리                                                    │
│                                                                                                  │
│   [향후 방향]                                                                                    │
│   Contrastive + Adversarial 하이브리드 접근 → 4th 버전 설계                                    │
│                                                                                                  │
└─────────────────────────────────────────────────────────────────────────────────────────────────┘
```

---

*작성일: 2026-01-30*
*버전: 3rd (Gender-Aware Score-Based Contrastive Learning)*
*실험 환경: DETR-R50, FAAP Dataset, 24 Epochs, ε=0.10*
